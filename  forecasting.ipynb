{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DSAI HW1 Peak Load Forecasting\n",
    "請根據台電歷史資料，預測未來七天的\"電力尖峰負載\"(MW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Solitude6060/anaconda3/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "/Users/Solitude6060/anaconda3/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: compiletime version 3.6 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.5\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential \n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read data and parser - \n",
    "將CSV資料讀入後以逗號拆開，只取包含時間前4個feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readfile(path):\n",
    "    file = open(path, \"r+\")\n",
    "    f = file.readlines()\n",
    "    return_tp_list = []\n",
    "    test_list = []\n",
    "    for i in f[1:366]:\n",
    "        #print(i)\n",
    "        day_list = i[:-1].split(\",\")\n",
    "        temp_list = []\n",
    "        for d in day_list[:2]:\n",
    "            temp_list.append(d)\n",
    "        for d in day_list[3:5]:\n",
    "            temp_list.append(d)\n",
    "        test_list.append(day_list[2])\n",
    "        #print(temp_list)\n",
    "        #print(len(temp_list))\n",
    "        return_tp_list.append(temp_list)\n",
    "    \n",
    "    return return_tp_list, test_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "取2017和2018年的資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp_2017, target_2017_list = readfile('data/taipower_2017.csv')\n",
    "tp_2018, target_2018_list = readfile('data/taipower_2018.csv')\n",
    "\n",
    "#print(tp_2018)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parser data ，取去年同一時間和上一週的資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sliceData(tp_data_2017, tp_data_2018):\n",
    "    #index = 1\n",
    "    con_list = []\n",
    "    data_2017_list = []\n",
    "    for t in range(len(tp_data_2017[:-1])):\n",
    "        if (t+1) % 7 is not 0:\n",
    "            con_list += tp_data_2017[t][1:]\n",
    "        else:\n",
    "            #if t is 0:\n",
    "            con_list += tp_data_2017[t][1:]\n",
    "            data_2017_list.append(con_list)\n",
    "            con_list = []\n",
    "    \n",
    "    con_list = []\n",
    "    data_2018_list = []\n",
    "    for t in range(len(tp_data_2018[:-1])):\n",
    "        if (t+1) % 7 is not 0:\n",
    "            con_list += tp_data_2018[t][1:]\n",
    "            #print(con_list)\n",
    "        else:\n",
    "            #if t is 0:\n",
    "            con_list += tp_data_2018[t][1:]    \n",
    "            data_2018_list.append(con_list)\n",
    "            con_list = []\n",
    "    \n",
    "    #print(\"2017\", data_2017_list[0])\n",
    "    #print(\"2018\", data_2018_list[0])\n",
    "    train_list = []\n",
    "    temp_list =[]\n",
    "    for i in range(len(data_2017_list)):\n",
    "        if i == 0:\n",
    "            temp_list = data_2017_list[i] + data_2017_list[-1]\n",
    "            #print(\"i = 0\", temp_list)\n",
    "        else:\n",
    "            temp_list = data_2017_list[i] + data_2017_list[i]\n",
    "            #print(\"i != 0\", temp_list)\n",
    "        train_list.append(temp_list)\n",
    "    \n",
    "    return train_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_X = sliceData(tp_2017, tp_2018)\n",
    "#print(train_X[0])\n",
    "#print(len(train_X[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "取得Training target，也就是training data中實際的尖峰負載預測值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTrainY(target_list):\n",
    "    train_y_list = []\n",
    "    con_list = []\n",
    "    for i in range(len(target_list[:-1])):\n",
    "        if (i+1) % 7 is not 0:\n",
    "            con_list.append(target_list[i])\n",
    "        else:\n",
    "            con_list.append(target_list[i])\n",
    "            train_y_list.append(con_list)\n",
    "            con_list = []\n",
    "    return train_y_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_Y = getTrainY(target_2018_list)\n",
    "np_train_X = np.array(train_X)\n",
    "np_train_Y = np.array(train_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bulid Model\n",
    "以Keras開發，用NN概念實現Linear regression\n",
    "以多層Dense，最後一層output 1x7 向量代表整週的預測"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bulidModel(x_shape):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units=256, input_shape=(x_shape[1], ), activation='linear'))\n",
    "    model.add(Dense(units=64,activation='linear'))\n",
    "    model.add(Dense(units=32,activation='linear'))\n",
    "    model.add(Dense(units=7,activation='linear'))\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss function\n",
    "root_mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def root_mean_squared_error(y_true, y_pred):\n",
    "    return K.sqrt(K.mean(K.square(y_pred - y_true), axis=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_7 (Dense)              (None, 256)               11008     \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 64)                16448     \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 7)                 231       \n",
      "=================================================================\n",
      "Total params: 29,767\n",
      "Trainable params: 29,767\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "LinearModel = bulidModel(np_train_X.shape)\n",
    "LinearModel.compile(loss=root_mean_squared_error, optimizer='rmsprop')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 41 samples, validate on 11 samples\n",
      "Epoch 1/1000\n",
      "41/41 [==============================] - 0s 153us/step - loss: 2397.3533 - val_loss: 1408.7047\n",
      "Epoch 2/1000\n",
      "41/41 [==============================] - 0s 146us/step - loss: 2688.0845 - val_loss: 2888.3931\n",
      "Epoch 3/1000\n",
      "41/41 [==============================] - 0s 151us/step - loss: 2462.8882 - val_loss: 1884.4730\n",
      "Epoch 4/1000\n",
      "41/41 [==============================] - 0s 190us/step - loss: 2940.8008 - val_loss: 2399.5620\n",
      "Epoch 5/1000\n",
      "41/41 [==============================] - 0s 123us/step - loss: 2204.3215 - val_loss: 1349.9144\n",
      "Epoch 6/1000\n",
      "41/41 [==============================] - 0s 102us/step - loss: 2269.0334 - val_loss: 2205.9800\n",
      "Epoch 7/1000\n",
      "41/41 [==============================] - 0s 85us/step - loss: 2045.3301 - val_loss: 1267.9923\n",
      "Epoch 8/1000\n",
      "41/41 [==============================] - 0s 94us/step - loss: 2155.9314 - val_loss: 2341.7021\n",
      "Epoch 9/1000\n",
      "41/41 [==============================] - 0s 93us/step - loss: 2161.1418 - val_loss: 1397.6359\n",
      "Epoch 10/1000\n",
      "41/41 [==============================] - 0s 98us/step - loss: 2350.8286 - val_loss: 2537.0874\n",
      "Epoch 11/1000\n",
      "41/41 [==============================] - 0s 88us/step - loss: 2246.1345 - val_loss: 1289.5380\n",
      "Epoch 12/1000\n",
      "41/41 [==============================] - 0s 92us/step - loss: 2398.6116 - val_loss: 2562.9482\n",
      "Epoch 13/1000\n",
      "41/41 [==============================] - 0s 98us/step - loss: 2273.9487 - val_loss: 1160.5990\n",
      "Epoch 14/1000\n",
      "41/41 [==============================] - 0s 116us/step - loss: 2312.1189 - val_loss: 2550.5889\n",
      "Epoch 15/1000\n",
      "41/41 [==============================] - 0s 103us/step - loss: 2206.4712 - val_loss: 1092.9985\n",
      "Epoch 16/1000\n",
      "41/41 [==============================] - 0s 197us/step - loss: 2402.6340 - val_loss: 2743.4717\n",
      "Epoch 17/1000\n",
      "41/41 [==============================] - 0s 129us/step - loss: 2286.5386 - val_loss: 1337.0723\n",
      "Epoch 18/1000\n",
      "41/41 [==============================] - 0s 123us/step - loss: 2681.4783 - val_loss: 3166.0181\n",
      "Epoch 19/1000\n",
      "41/41 [==============================] - 0s 176us/step - loss: 2640.1201 - val_loss: 1776.7605\n",
      "Epoch 20/1000\n",
      "41/41 [==============================] - 0s 119us/step - loss: 3007.3037 - val_loss: 2691.9131\n",
      "Epoch 21/1000\n",
      "41/41 [==============================] - 0s 150us/step - loss: 2259.0244 - val_loss: 1286.4371\n",
      "Epoch 22/1000\n",
      "41/41 [==============================] - 0s 192us/step - loss: 2536.0461 - val_loss: 2622.5852\n",
      "Epoch 23/1000\n",
      "41/41 [==============================] - 0s 113us/step - loss: 2204.0464 - val_loss: 1157.7684\n",
      "Epoch 24/1000\n",
      "41/41 [==============================] - 0s 127us/step - loss: 2382.1187 - val_loss: 2433.4941\n",
      "Epoch 25/1000\n",
      "41/41 [==============================] - 0s 178us/step - loss: 2065.3467 - val_loss: 1037.1616\n",
      "Epoch 26/1000\n",
      "41/41 [==============================] - 0s 116us/step - loss: 2227.2878 - val_loss: 2615.9744\n",
      "Epoch 27/1000\n",
      "41/41 [==============================] - 0s 113us/step - loss: 2179.2747 - val_loss: 1242.1171\n",
      "Epoch 28/1000\n",
      "41/41 [==============================] - 0s 120us/step - loss: 2466.5981 - val_loss: 2904.0806\n",
      "Epoch 29/1000\n",
      "41/41 [==============================] - 0s 164us/step - loss: 2460.1143 - val_loss: 1308.3116\n",
      "Epoch 30/1000\n",
      "41/41 [==============================] - 0s 118us/step - loss: 2588.5488 - val_loss: 2762.7581\n",
      "Epoch 31/1000\n",
      "41/41 [==============================] - 0s 149us/step - loss: 2283.2014 - val_loss: 1527.9901\n",
      "Epoch 32/1000\n",
      "41/41 [==============================] - 0s 128us/step - loss: 2865.4963 - val_loss: 3191.6345\n",
      "Epoch 33/1000\n",
      "41/41 [==============================] - 0s 144us/step - loss: 2683.1226 - val_loss: 1354.2694\n",
      "Epoch 34/1000\n",
      "41/41 [==============================] - 0s 190us/step - loss: 2667.0134 - val_loss: 2541.5957\n",
      "Epoch 35/1000\n",
      "41/41 [==============================] - 0s 122us/step - loss: 2178.3694 - val_loss: 1159.7117\n",
      "Epoch 36/1000\n",
      "41/41 [==============================] - 0s 138us/step - loss: 2400.7637 - val_loss: 2572.5266\n",
      "Epoch 37/1000\n",
      "41/41 [==============================] - 0s 131us/step - loss: 2197.4187 - val_loss: 1215.5955\n",
      "Epoch 38/1000\n",
      "41/41 [==============================] - 0s 182us/step - loss: 2383.3271 - val_loss: 2433.2205\n",
      "Epoch 39/1000\n",
      "41/41 [==============================] - 0s 147us/step - loss: 2098.5459 - val_loss: 1172.6115\n",
      "Epoch 40/1000\n",
      "41/41 [==============================] - 0s 164us/step - loss: 2315.6289 - val_loss: 2447.3577\n",
      "Epoch 41/1000\n",
      "41/41 [==============================] - 0s 129us/step - loss: 2154.4590 - val_loss: 1265.9980\n",
      "Epoch 42/1000\n",
      "41/41 [==============================] - 0s 114us/step - loss: 2389.2300 - val_loss: 2436.2627\n",
      "Epoch 43/1000\n",
      "41/41 [==============================] - 0s 213us/step - loss: 2292.1067 - val_loss: 1214.2086\n",
      "Epoch 44/1000\n",
      "41/41 [==============================] - 0s 200us/step - loss: 2146.2705 - val_loss: 2124.2942\n",
      "Epoch 45/1000\n",
      "41/41 [==============================] - 0s 110us/step - loss: 2101.0667 - val_loss: 1308.1661\n",
      "Epoch 46/1000\n",
      "41/41 [==============================] - 0s 101us/step - loss: 2146.7297 - val_loss: 2231.6892\n",
      "Epoch 47/1000\n",
      "41/41 [==============================] - 0s 132us/step - loss: 2164.1970 - val_loss: 1427.9191\n",
      "Epoch 48/1000\n",
      "41/41 [==============================] - 0s 142us/step - loss: 2304.9692 - val_loss: 2880.0952\n",
      "Epoch 49/1000\n",
      "41/41 [==============================] - 0s 177us/step - loss: 2505.1113 - val_loss: 1817.7582\n",
      "Epoch 50/1000\n",
      "41/41 [==============================] - 0s 390us/step - loss: 3064.6492 - val_loss: 3905.1055\n",
      "Epoch 51/1000\n",
      "41/41 [==============================] - 0s 227us/step - loss: 3132.3726 - val_loss: 1867.7195\n",
      "Epoch 52/1000\n",
      "41/41 [==============================] - 0s 156us/step - loss: 3244.5647 - val_loss: 2658.2620\n",
      "Epoch 53/1000\n",
      "41/41 [==============================] - 0s 176us/step - loss: 2184.5527 - val_loss: 1241.5083\n",
      "Epoch 54/1000\n",
      "41/41 [==============================] - 0s 162us/step - loss: 2595.9268 - val_loss: 2449.9268\n",
      "Epoch 55/1000\n",
      "41/41 [==============================] - 0s 160us/step - loss: 2117.2283 - val_loss: 1058.0895\n",
      "Epoch 56/1000\n",
      "41/41 [==============================] - 0s 124us/step - loss: 2278.2012 - val_loss: 2445.7363\n",
      "Epoch 57/1000\n",
      "41/41 [==============================] - 0s 128us/step - loss: 2094.0767 - val_loss: 1025.2362\n",
      "Epoch 58/1000\n",
      "41/41 [==============================] - 0s 134us/step - loss: 2239.7314 - val_loss: 2600.2712\n",
      "Epoch 59/1000\n",
      "41/41 [==============================] - 0s 203us/step - loss: 2184.6206 - val_loss: 1254.8896\n",
      "Epoch 60/1000\n",
      "41/41 [==============================] - 0s 138us/step - loss: 2456.2766 - val_loss: 2673.1970\n",
      "Epoch 61/1000\n",
      "41/41 [==============================] - 0s 176us/step - loss: 2210.1575 - val_loss: 1398.4042\n",
      "Epoch 62/1000\n",
      "41/41 [==============================] - 0s 126us/step - loss: 2516.0967 - val_loss: 2495.2712\n",
      "Epoch 63/1000\n",
      "41/41 [==============================] - 0s 135us/step - loss: 2162.5178 - val_loss: 1311.6665\n",
      "Epoch 64/1000\n",
      "41/41 [==============================] - 0s 136us/step - loss: 2318.2043 - val_loss: 2340.3899\n",
      "Epoch 65/1000\n",
      "41/41 [==============================] - 0s 137us/step - loss: 2057.5864 - val_loss: 1135.2300\n",
      "Epoch 66/1000\n",
      "41/41 [==============================] - 0s 197us/step - loss: 2189.3362 - val_loss: 2604.0830\n",
      "Epoch 67/1000\n",
      "41/41 [==============================] - 0s 150us/step - loss: 2189.6172 - val_loss: 1291.8201\n",
      "Epoch 68/1000\n",
      "41/41 [==============================] - 0s 179us/step - loss: 2564.7041 - val_loss: 3079.8562\n",
      "Epoch 69/1000\n",
      "41/41 [==============================] - 0s 155us/step - loss: 2540.5017 - val_loss: 1710.4031\n",
      "Epoch 70/1000\n",
      "41/41 [==============================] - 0s 145us/step - loss: 3042.3242 - val_loss: 3317.9766\n",
      "Epoch 71/1000\n",
      "41/41 [==============================] - 0s 134us/step - loss: 2720.4580 - val_loss: 1668.0375\n",
      "Epoch 72/1000\n",
      "41/41 [==============================] - 0s 129us/step - loss: 2960.7920 - val_loss: 2913.3987\n",
      "Epoch 73/1000\n",
      "41/41 [==============================] - 0s 123us/step - loss: 2464.0264 - val_loss: 1213.1270\n",
      "Epoch 74/1000\n",
      "41/41 [==============================] - 0s 134us/step - loss: 2535.8418 - val_loss: 2599.8174\n",
      "Epoch 75/1000\n",
      "41/41 [==============================] - 0s 124us/step - loss: 2127.1511 - val_loss: 1258.4570\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76/1000\n",
      "41/41 [==============================] - 0s 115us/step - loss: 2575.5942 - val_loss: 2683.3423\n",
      "Epoch 77/1000\n",
      "41/41 [==============================] - 0s 107us/step - loss: 2264.5212 - val_loss: 1300.4381\n",
      "Epoch 78/1000\n",
      "41/41 [==============================] - 0s 100us/step - loss: 2485.3508 - val_loss: 2401.2146\n",
      "Epoch 79/1000\n",
      "41/41 [==============================] - 0s 131us/step - loss: 2141.8665 - val_loss: 1180.4536\n",
      "Epoch 80/1000\n",
      "41/41 [==============================] - 0s 126us/step - loss: 2164.8103 - val_loss: 2330.9709\n",
      "Epoch 81/1000\n",
      "41/41 [==============================] - 0s 139us/step - loss: 2173.2041 - val_loss: 1390.1759\n",
      "Epoch 82/1000\n",
      "41/41 [==============================] - 0s 332us/step - loss: 2251.2478 - val_loss: 2207.4905\n",
      "Epoch 83/1000\n",
      "41/41 [==============================] - 0s 131us/step - loss: 2159.0513 - val_loss: 1536.8851\n",
      "Epoch 84/1000\n",
      "41/41 [==============================] - 0s 158us/step - loss: 2229.3701 - val_loss: 2096.8608\n",
      "Epoch 85/1000\n",
      "41/41 [==============================] - 0s 137us/step - loss: 2167.7563 - val_loss: 1660.6782\n",
      "Epoch 86/1000\n",
      "41/41 [==============================] - 0s 124us/step - loss: 2190.0498 - val_loss: 1872.2551\n",
      "Epoch 87/1000\n",
      "41/41 [==============================] - 0s 135us/step - loss: 2199.2634 - val_loss: 2025.5962\n",
      "Epoch 88/1000\n",
      "41/41 [==============================] - 0s 119us/step - loss: 2146.7517 - val_loss: 1599.6136\n",
      "Epoch 89/1000\n",
      "41/41 [==============================] - 0s 128us/step - loss: 2428.4146 - val_loss: 2847.8748\n",
      "Epoch 90/1000\n",
      "41/41 [==============================] - 0s 138us/step - loss: 2390.2666 - val_loss: 1479.7831\n",
      "Epoch 91/1000\n",
      "41/41 [==============================] - 0s 177us/step - loss: 2709.6958 - val_loss: 3327.0811\n",
      "Epoch 92/1000\n",
      "41/41 [==============================] - 0s 139us/step - loss: 2583.8345 - val_loss: 1800.8530\n",
      "Epoch 93/1000\n",
      "41/41 [==============================] - 0s 143us/step - loss: 3208.9307 - val_loss: 3122.0823\n",
      "Epoch 94/1000\n",
      "41/41 [==============================] - 0s 266us/step - loss: 2412.1045 - val_loss: 1136.5955\n",
      "Epoch 95/1000\n",
      "41/41 [==============================] - 0s 145us/step - loss: 2646.0576 - val_loss: 2740.0498\n",
      "Epoch 96/1000\n",
      "41/41 [==============================] - 0s 192us/step - loss: 2282.0278 - val_loss: 1063.8901\n",
      "Epoch 97/1000\n",
      "41/41 [==============================] - 0s 137us/step - loss: 2394.7402 - val_loss: 2495.9329\n",
      "Epoch 98/1000\n",
      "41/41 [==============================] - 0s 151us/step - loss: 2092.3640 - val_loss: 884.3986\n",
      "Epoch 99/1000\n",
      "41/41 [==============================] - 0s 149us/step - loss: 2279.6365 - val_loss: 2640.6458\n",
      "Epoch 100/1000\n",
      "41/41 [==============================] - 0s 178us/step - loss: 2169.8201 - val_loss: 1105.5336\n",
      "Epoch 101/1000\n",
      "41/41 [==============================] - 0s 169us/step - loss: 2385.4504 - val_loss: 2733.5803\n",
      "Epoch 102/1000\n",
      "41/41 [==============================] - 0s 168us/step - loss: 2255.5715 - val_loss: 1236.7284\n",
      "Epoch 103/1000\n",
      "41/41 [==============================] - 0s 130us/step - loss: 2457.0437 - val_loss: 2552.8599\n",
      "Epoch 104/1000\n",
      "41/41 [==============================] - 0s 138us/step - loss: 2109.3267 - val_loss: 1063.1750\n",
      "Epoch 105/1000\n",
      "41/41 [==============================] - 0s 161us/step - loss: 2276.9885 - val_loss: 2559.5127\n",
      "Epoch 106/1000\n",
      "41/41 [==============================] - 0s 115us/step - loss: 2136.0715 - val_loss: 1113.6328\n",
      "Epoch 107/1000\n",
      "41/41 [==============================] - 0s 152us/step - loss: 2272.7373 - val_loss: 2390.6638\n",
      "Epoch 108/1000\n",
      "41/41 [==============================] - 0s 149us/step - loss: 2064.4912 - val_loss: 1148.6857\n",
      "Epoch 109/1000\n",
      "41/41 [==============================] - 0s 169us/step - loss: 2229.1707 - val_loss: 2538.9534\n",
      "Epoch 110/1000\n",
      "41/41 [==============================] - 0s 147us/step - loss: 2221.1646 - val_loss: 1384.5017\n",
      "Epoch 111/1000\n",
      "41/41 [==============================] - 0s 152us/step - loss: 2470.4231 - val_loss: 2691.9814\n",
      "Epoch 112/1000\n",
      "41/41 [==============================] - 0s 167us/step - loss: 2283.9751 - val_loss: 1185.1390\n",
      "Epoch 113/1000\n",
      "41/41 [==============================] - 0s 158us/step - loss: 2466.0647 - val_loss: 2791.4568\n",
      "Epoch 114/1000\n",
      "41/41 [==============================] - 0s 158us/step - loss: 2326.2368 - val_loss: 1359.8263\n",
      "Epoch 115/1000\n",
      "41/41 [==============================] - 0s 110us/step - loss: 2625.9387 - val_loss: 2808.1223\n",
      "Epoch 116/1000\n",
      "41/41 [==============================] - 0s 186us/step - loss: 2381.0623 - val_loss: 1409.6713\n",
      "Epoch 117/1000\n",
      "41/41 [==============================] - 0s 144us/step - loss: 2627.4875 - val_loss: 2640.9573\n",
      "Epoch 118/1000\n",
      "41/41 [==============================] - 0s 147us/step - loss: 2206.6814 - val_loss: 1331.5044\n",
      "Epoch 119/1000\n",
      "41/41 [==============================] - 0s 131us/step - loss: 2577.2375 - val_loss: 2788.3137\n",
      "Epoch 120/1000\n",
      "41/41 [==============================] - 0s 140us/step - loss: 2264.2861 - val_loss: 1435.5287\n",
      "Epoch 121/1000\n",
      "41/41 [==============================] - 0s 143us/step - loss: 2653.2605 - val_loss: 2917.8005\n",
      "Epoch 122/1000\n",
      "41/41 [==============================] - 0s 192us/step - loss: 2380.2654 - val_loss: 1172.9325\n",
      "Epoch 123/1000\n",
      "41/41 [==============================] - 0s 116us/step - loss: 2435.6013 - val_loss: 2536.7803\n",
      "Epoch 124/1000\n",
      "41/41 [==============================] - 0s 135us/step - loss: 2082.6924 - val_loss: 1080.7983\n",
      "Epoch 125/1000\n",
      "41/41 [==============================] - 0s 151us/step - loss: 2360.5164 - val_loss: 2794.4080\n",
      "Epoch 126/1000\n",
      "41/41 [==============================] - 0s 143us/step - loss: 2400.1348 - val_loss: 1436.1708\n",
      "Epoch 127/1000\n",
      "41/41 [==============================] - 0s 162us/step - loss: 2543.3235 - val_loss: 2758.2810\n",
      "Epoch 128/1000\n",
      "41/41 [==============================] - 0s 147us/step - loss: 2459.0789 - val_loss: 1990.1781\n",
      "Epoch 129/1000\n",
      "41/41 [==============================] - 0s 122us/step - loss: 3009.0601 - val_loss: 2613.1033\n",
      "Epoch 130/1000\n",
      "41/41 [==============================] - 0s 153us/step - loss: 2466.7463 - val_loss: 1345.5116\n",
      "Epoch 131/1000\n",
      "41/41 [==============================] - 0s 149us/step - loss: 2249.4314 - val_loss: 2328.1609\n",
      "Epoch 132/1000\n",
      "41/41 [==============================] - 0s 141us/step - loss: 2141.8433 - val_loss: 1332.2606\n",
      "Epoch 133/1000\n",
      "41/41 [==============================] - 0s 172us/step - loss: 2291.5586 - val_loss: 2703.2341\n",
      "Epoch 134/1000\n",
      "41/41 [==============================] - 0s 183us/step - loss: 2278.8069 - val_loss: 1263.5161\n",
      "Epoch 135/1000\n",
      "41/41 [==============================] - 0s 136us/step - loss: 2567.6184 - val_loss: 3108.4773\n",
      "Epoch 136/1000\n",
      "41/41 [==============================] - 0s 134us/step - loss: 2444.8110 - val_loss: 1557.9116\n",
      "Epoch 137/1000\n",
      "41/41 [==============================] - 0s 126us/step - loss: 2842.7505 - val_loss: 3094.7571\n",
      "Epoch 138/1000\n",
      "41/41 [==============================] - 0s 151us/step - loss: 2499.2471 - val_loss: 1539.7753\n",
      "Epoch 139/1000\n",
      "41/41 [==============================] - 0s 158us/step - loss: 2754.0464 - val_loss: 2507.5271\n",
      "Epoch 140/1000\n",
      "41/41 [==============================] - 0s 219us/step - loss: 2108.5723 - val_loss: 1214.0629\n",
      "Epoch 141/1000\n",
      "41/41 [==============================] - 0s 155us/step - loss: 2265.8633 - val_loss: 2368.1477\n",
      "Epoch 142/1000\n",
      "41/41 [==============================] - 0s 130us/step - loss: 2111.6655 - val_loss: 1578.1554\n",
      "Epoch 143/1000\n",
      "41/41 [==============================] - 0s 141us/step - loss: 2309.7544 - val_loss: 1992.3441\n",
      "Epoch 144/1000\n",
      "41/41 [==============================] - 0s 121us/step - loss: 2077.5793 - val_loss: 1803.2500\n",
      "Epoch 145/1000\n",
      "41/41 [==============================] - 0s 130us/step - loss: 2155.8701 - val_loss: 1827.5604\n",
      "Epoch 146/1000\n",
      "41/41 [==============================] - 0s 121us/step - loss: 2161.5234 - val_loss: 2009.2540\n",
      "Epoch 147/1000\n",
      "41/41 [==============================] - 0s 128us/step - loss: 2193.1479 - val_loss: 1702.6586\n",
      "Epoch 148/1000\n",
      "41/41 [==============================] - 0s 147us/step - loss: 2139.6331 - val_loss: 2159.8203\n",
      "Epoch 149/1000\n",
      "41/41 [==============================] - 0s 131us/step - loss: 2131.7834 - val_loss: 1608.7294\n",
      "Epoch 150/1000\n",
      "41/41 [==============================] - 0s 137us/step - loss: 2361.2209 - val_loss: 2509.0322\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 151/1000\n",
      "41/41 [==============================] - 0s 116us/step - loss: 2165.3416 - val_loss: 1273.0001\n",
      "Epoch 152/1000\n",
      "41/41 [==============================] - 0s 136us/step - loss: 2560.3401 - val_loss: 3115.5667\n",
      "Epoch 153/1000\n",
      "41/41 [==============================] - 0s 135us/step - loss: 2409.7859 - val_loss: 1302.7194\n",
      "Epoch 154/1000\n",
      "41/41 [==============================] - 0s 110us/step - loss: 2876.6089 - val_loss: 2908.6816\n",
      "Epoch 155/1000\n",
      "41/41 [==============================] - 0s 139us/step - loss: 2328.5381 - val_loss: 1186.0753\n",
      "Epoch 156/1000\n",
      "41/41 [==============================] - 0s 131us/step - loss: 2624.1633 - val_loss: 2755.1499\n",
      "Epoch 157/1000\n",
      "41/41 [==============================] - 0s 134us/step - loss: 2227.7981 - val_loss: 1093.7794\n",
      "Epoch 158/1000\n",
      "41/41 [==============================] - 0s 125us/step - loss: 2447.1853 - val_loss: 2640.4558\n",
      "Epoch 159/1000\n",
      "41/41 [==============================] - 0s 133us/step - loss: 2150.3179 - val_loss: 1053.0114\n",
      "Epoch 160/1000\n",
      "41/41 [==============================] - 0s 151us/step - loss: 2328.3347 - val_loss: 2771.8279\n",
      "Epoch 161/1000\n",
      "41/41 [==============================] - 0s 137us/step - loss: 2234.0198 - val_loss: 1183.5219\n",
      "Epoch 162/1000\n",
      "41/41 [==============================] - 0s 114us/step - loss: 2436.6907 - val_loss: 2593.0891\n",
      "Epoch 163/1000\n",
      "41/41 [==============================] - 0s 104us/step - loss: 2122.5334 - val_loss: 1121.3156\n",
      "Epoch 164/1000\n",
      "41/41 [==============================] - 0s 94us/step - loss: 2346.7747 - val_loss: 2683.4094\n",
      "Epoch 165/1000\n",
      "41/41 [==============================] - 0s 147us/step - loss: 2157.4622 - val_loss: 1149.9338\n",
      "Epoch 166/1000\n",
      "41/41 [==============================] - 0s 119us/step - loss: 2427.1201 - val_loss: 2652.7444\n",
      "Epoch 167/1000\n",
      "41/41 [==============================] - 0s 88us/step - loss: 2223.5347 - val_loss: 1275.2440\n",
      "Epoch 168/1000\n",
      "41/41 [==============================] - 0s 93us/step - loss: 2435.8745 - val_loss: 2558.7158\n",
      "Epoch 169/1000\n",
      "41/41 [==============================] - 0s 128us/step - loss: 2159.4026 - val_loss: 1188.3157\n",
      "Epoch 170/1000\n",
      "41/41 [==============================] - 0s 114us/step - loss: 2359.5942 - val_loss: 2544.7107\n",
      "Epoch 171/1000\n",
      "41/41 [==============================] - 0s 149us/step - loss: 2123.1936 - val_loss: 1094.3495\n",
      "Epoch 172/1000\n",
      "41/41 [==============================] - 0s 115us/step - loss: 2375.8677 - val_loss: 2709.0159\n",
      "Epoch 173/1000\n",
      "41/41 [==============================] - 0s 104us/step - loss: 2227.6423 - val_loss: 1227.7574\n",
      "Epoch 174/1000\n",
      "41/41 [==============================] - 0s 105us/step - loss: 2472.2073 - val_loss: 2570.3491\n",
      "Epoch 175/1000\n",
      "41/41 [==============================] - 0s 223us/step - loss: 2156.0508 - val_loss: 1169.1687\n",
      "Epoch 176/1000\n",
      "41/41 [==============================] - 0s 111us/step - loss: 2449.6809 - val_loss: 2485.3743\n",
      "Epoch 177/1000\n",
      "41/41 [==============================] - 0s 112us/step - loss: 2175.3198 - val_loss: 1185.2252\n",
      "Epoch 178/1000\n",
      "41/41 [==============================] - 0s 171us/step - loss: 2354.6257 - val_loss: 2442.5037\n",
      "Epoch 179/1000\n",
      "41/41 [==============================] - 0s 145us/step - loss: 2176.1519 - val_loss: 1084.3102\n",
      "Epoch 180/1000\n",
      "41/41 [==============================] - 0s 120us/step - loss: 2246.7278 - val_loss: 2706.4419\n",
      "Epoch 181/1000\n",
      "41/41 [==============================] - 0s 195us/step - loss: 2273.9480 - val_loss: 1311.3032\n",
      "Epoch 182/1000\n",
      "41/41 [==============================] - 0s 113us/step - loss: 2553.1477 - val_loss: 2809.7827\n",
      "Epoch 183/1000\n",
      "41/41 [==============================] - 0s 147us/step - loss: 2335.2896 - val_loss: 1347.2256\n",
      "Epoch 184/1000\n",
      "41/41 [==============================] - 0s 145us/step - loss: 2511.1670 - val_loss: 2626.0781\n",
      "Epoch 185/1000\n",
      "41/41 [==============================] - 0s 124us/step - loss: 2166.7104 - val_loss: 1228.1333\n",
      "Epoch 186/1000\n",
      "41/41 [==============================] - 0s 120us/step - loss: 2460.5491 - val_loss: 2696.6682\n",
      "Epoch 187/1000\n",
      "41/41 [==============================] - 0s 231us/step - loss: 2226.6348 - val_loss: 1274.2343\n",
      "Epoch 188/1000\n",
      "41/41 [==============================] - 0s 110us/step - loss: 2450.9170 - val_loss: 2482.2048\n",
      "Epoch 189/1000\n",
      "41/41 [==============================] - 0s 117us/step - loss: 2067.4946 - val_loss: 963.8317\n",
      "Epoch 190/1000\n",
      "41/41 [==============================] - 0s 109us/step - loss: 2233.9402 - val_loss: 2724.6799\n",
      "Epoch 191/1000\n",
      "41/41 [==============================] - 0s 127us/step - loss: 2158.1003 - val_loss: 990.1111\n",
      "Epoch 192/1000\n",
      "41/41 [==============================] - 0s 141us/step - loss: 2452.5674 - val_loss: 2834.4651\n",
      "Epoch 193/1000\n",
      "41/41 [==============================] - 0s 122us/step - loss: 2313.9355 - val_loss: 1355.8041\n",
      "Epoch 194/1000\n",
      "41/41 [==============================] - 0s 196us/step - loss: 2524.8728 - val_loss: 2540.6062\n",
      "Epoch 195/1000\n",
      "41/41 [==============================] - 0s 133us/step - loss: 2128.9224 - val_loss: 1183.0859\n",
      "Epoch 196/1000\n",
      "41/41 [==============================] - 0s 99us/step - loss: 2394.8030 - val_loss: 2634.3933\n",
      "Epoch 197/1000\n",
      "41/41 [==============================] - 0s 138us/step - loss: 2181.7979 - val_loss: 1277.9478\n",
      "Epoch 198/1000\n",
      "41/41 [==============================] - 0s 132us/step - loss: 2425.2678 - val_loss: 2507.0342\n",
      "Epoch 199/1000\n",
      "41/41 [==============================] - 0s 121us/step - loss: 2085.8708 - val_loss: 1083.7124\n",
      "Epoch 200/1000\n",
      "41/41 [==============================] - 0s 100us/step - loss: 2305.0183 - val_loss: 2672.6423\n",
      "Epoch 201/1000\n",
      "41/41 [==============================] - 0s 125us/step - loss: 2178.1218 - val_loss: 1096.3412\n",
      "Epoch 202/1000\n",
      "41/41 [==============================] - 0s 153us/step - loss: 2382.7266 - val_loss: 2505.4336\n",
      "Epoch 203/1000\n",
      "41/41 [==============================] - 0s 101us/step - loss: 2108.2729 - val_loss: 1002.0143\n",
      "Epoch 204/1000\n",
      "41/41 [==============================] - 0s 113us/step - loss: 2320.0647 - val_loss: 2726.6970\n",
      "Epoch 205/1000\n",
      "41/41 [==============================] - 0s 127us/step - loss: 2237.1860 - val_loss: 1215.5175\n",
      "Epoch 206/1000\n",
      "41/41 [==============================] - 0s 103us/step - loss: 2538.6362 - val_loss: 2919.8438\n",
      "Epoch 207/1000\n",
      "41/41 [==============================] - 0s 124us/step - loss: 2382.6299 - val_loss: 1286.6382\n",
      "Epoch 208/1000\n",
      "41/41 [==============================] - 0s 92us/step - loss: 2595.5171 - val_loss: 2633.3362\n",
      "Epoch 209/1000\n",
      "41/41 [==============================] - 0s 117us/step - loss: 2138.5598 - val_loss: 1096.6818\n",
      "Epoch 210/1000\n",
      "41/41 [==============================] - 0s 147us/step - loss: 2441.5869 - val_loss: 2637.6240\n",
      "Epoch 211/1000\n",
      "41/41 [==============================] - 0s 129us/step - loss: 2111.6658 - val_loss: 1025.5194\n",
      "Epoch 212/1000\n",
      "41/41 [==============================] - 0s 120us/step - loss: 2361.8247 - val_loss: 2662.3801\n",
      "Epoch 213/1000\n",
      "41/41 [==============================] - 0s 104us/step - loss: 2193.9441 - val_loss: 1168.4659\n",
      "Epoch 214/1000\n",
      "41/41 [==============================] - 0s 101us/step - loss: 2343.6113 - val_loss: 2421.6858\n",
      "Epoch 215/1000\n",
      "41/41 [==============================] - 0s 117us/step - loss: 2093.5681 - val_loss: 1253.4214\n",
      "Epoch 216/1000\n",
      "41/41 [==============================] - 0s 104us/step - loss: 2210.9121 - val_loss: 2280.4248\n",
      "Epoch 217/1000\n",
      "41/41 [==============================] - 0s 137us/step - loss: 2074.2654 - val_loss: 1376.8098\n",
      "Epoch 218/1000\n",
      "41/41 [==============================] - 0s 157us/step - loss: 2160.8435 - val_loss: 2193.6428\n",
      "Epoch 219/1000\n",
      "41/41 [==============================] - 0s 139us/step - loss: 2015.2751 - val_loss: 1274.1302\n",
      "Epoch 220/1000\n",
      "41/41 [==============================] - 0s 106us/step - loss: 2116.2300 - val_loss: 2373.6194\n",
      "Epoch 221/1000\n",
      "41/41 [==============================] - 0s 103us/step - loss: 2133.7092 - val_loss: 1464.2450\n",
      "Epoch 222/1000\n",
      "41/41 [==============================] - 0s 107us/step - loss: 2370.1685 - val_loss: 2370.5461\n",
      "Epoch 223/1000\n",
      "41/41 [==============================] - 0s 113us/step - loss: 2248.7346 - val_loss: 1773.5304\n",
      "Epoch 224/1000\n",
      "41/41 [==============================] - 0s 137us/step - loss: 2356.0708 - val_loss: 2313.9724\n",
      "Epoch 225/1000\n",
      "41/41 [==============================] - 0s 147us/step - loss: 2562.7878 - val_loss: 2449.0039\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 226/1000\n",
      "41/41 [==============================] - 0s 165us/step - loss: 2441.7141 - val_loss: 1435.9224\n",
      "Epoch 227/1000\n",
      "41/41 [==============================] - 0s 110us/step - loss: 2550.8684 - val_loss: 3265.9182\n",
      "Epoch 228/1000\n",
      "41/41 [==============================] - 0s 102us/step - loss: 2540.4214 - val_loss: 1424.0737\n",
      "Epoch 229/1000\n",
      "41/41 [==============================] - 0s 130us/step - loss: 2878.0811 - val_loss: 2865.8293\n",
      "Epoch 230/1000\n",
      "41/41 [==============================] - 0s 133us/step - loss: 2227.6411 - val_loss: 1032.7567\n",
      "Epoch 231/1000\n",
      "41/41 [==============================] - 0s 110us/step - loss: 2476.4080 - val_loss: 2741.1584\n",
      "Epoch 232/1000\n",
      "41/41 [==============================] - 0s 131us/step - loss: 2165.7869 - val_loss: 1007.3436\n",
      "Epoch 233/1000\n",
      "41/41 [==============================] - 0s 115us/step - loss: 2378.4319 - val_loss: 2624.0571\n",
      "Epoch 234/1000\n",
      "41/41 [==============================] - 0s 124us/step - loss: 2095.7922 - val_loss: 1023.4961\n",
      "Epoch 235/1000\n",
      "41/41 [==============================] - 0s 121us/step - loss: 2315.9805 - val_loss: 2608.9392\n",
      "Epoch 236/1000\n",
      "41/41 [==============================] - 0s 149us/step - loss: 2145.8301 - val_loss: 1190.1305\n",
      "Epoch 237/1000\n",
      "41/41 [==============================] - 0s 141us/step - loss: 2264.2834 - val_loss: 2412.2795\n",
      "Epoch 238/1000\n",
      "41/41 [==============================] - 0s 127us/step - loss: 2049.0708 - val_loss: 1076.9825\n",
      "Epoch 239/1000\n",
      "41/41 [==============================] - 0s 121us/step - loss: 2101.5146 - val_loss: 2540.4204\n",
      "Epoch 240/1000\n",
      "41/41 [==============================] - 0s 101us/step - loss: 2096.1904 - val_loss: 954.9241\n",
      "Epoch 241/1000\n",
      "41/41 [==============================] - 0s 106us/step - loss: 2277.9980 - val_loss: 2825.5278\n",
      "Epoch 242/1000\n",
      "41/41 [==============================] - 0s 118us/step - loss: 2267.7361 - val_loss: 1301.4930\n",
      "Epoch 243/1000\n",
      "41/41 [==============================] - 0s 122us/step - loss: 2601.5117 - val_loss: 2720.3225\n",
      "Epoch 244/1000\n",
      "41/41 [==============================] - 0s 138us/step - loss: 2229.2817 - val_loss: 1298.5940\n",
      "Epoch 245/1000\n",
      "41/41 [==============================] - 0s 179us/step - loss: 2494.8958 - val_loss: 2762.8806\n",
      "Epoch 246/1000\n",
      "41/41 [==============================] - 0s 161us/step - loss: 2257.8174 - val_loss: 1296.6659\n",
      "Epoch 247/1000\n",
      "41/41 [==============================] - 0s 159us/step - loss: 2477.3945 - val_loss: 2823.5803\n",
      "Epoch 248/1000\n",
      "41/41 [==============================] - 0s 175us/step - loss: 2263.1870 - val_loss: 1276.8282\n",
      "Epoch 249/1000\n",
      "41/41 [==============================] - 0s 151us/step - loss: 2523.7029 - val_loss: 2802.9885\n",
      "Epoch 250/1000\n",
      "41/41 [==============================] - 0s 158us/step - loss: 2232.2664 - val_loss: 1049.2906\n",
      "Epoch 251/1000\n",
      "41/41 [==============================] - 0s 140us/step - loss: 2323.3198 - val_loss: 2961.4885\n",
      "Epoch 252/1000\n",
      "41/41 [==============================] - 0s 178us/step - loss: 2320.1619 - val_loss: 1179.7476\n",
      "Epoch 253/1000\n",
      "41/41 [==============================] - 0s 183us/step - loss: 2586.0508 - val_loss: 2698.6006\n",
      "Epoch 254/1000\n",
      "41/41 [==============================] - 0s 246us/step - loss: 2272.9951 - val_loss: 1174.8832\n",
      "Epoch 255/1000\n",
      "41/41 [==============================] - 0s 210us/step - loss: 2346.2427 - val_loss: 2432.1331\n",
      "Epoch 256/1000\n",
      "41/41 [==============================] - 0s 215us/step - loss: 2078.6045 - val_loss: 1170.8867\n",
      "Epoch 257/1000\n",
      "41/41 [==============================] - 0s 228us/step - loss: 2313.3137 - val_loss: 2562.3401\n",
      "Epoch 258/1000\n",
      "41/41 [==============================] - 0s 171us/step - loss: 2158.8955 - val_loss: 1264.6556\n",
      "Epoch 259/1000\n",
      "41/41 [==============================] - 0s 167us/step - loss: 2397.7451 - val_loss: 2537.2561\n",
      "Epoch 260/1000\n",
      "41/41 [==============================] - 0s 193us/step - loss: 2128.2959 - val_loss: 1215.3536\n",
      "Epoch 261/1000\n",
      "41/41 [==============================] - 0s 186us/step - loss: 2367.5894 - val_loss: 2677.0542\n",
      "Epoch 262/1000\n",
      "41/41 [==============================] - 0s 167us/step - loss: 2150.5603 - val_loss: 1022.7830\n",
      "Epoch 263/1000\n",
      "41/41 [==============================] - 0s 200us/step - loss: 2405.0693 - val_loss: 2789.9519\n",
      "Epoch 264/1000\n",
      "41/41 [==============================] - 0s 215us/step - loss: 2226.5645 - val_loss: 961.5247\n",
      "Epoch 265/1000\n",
      "41/41 [==============================] - 0s 168us/step - loss: 2324.2166 - val_loss: 2592.2070\n",
      "Epoch 266/1000\n",
      "41/41 [==============================] - 0s 153us/step - loss: 2120.7539 - val_loss: 984.9701\n",
      "Epoch 267/1000\n",
      "41/41 [==============================] - 0s 159us/step - loss: 2267.3538 - val_loss: 2564.1221\n",
      "Epoch 268/1000\n",
      "41/41 [==============================] - 0s 212us/step - loss: 2105.5674 - val_loss: 1036.5531\n",
      "Epoch 269/1000\n",
      "41/41 [==============================] - 0s 172us/step - loss: 2261.4844 - val_loss: 2712.7305\n",
      "Epoch 270/1000\n",
      "41/41 [==============================] - 0s 208us/step - loss: 2212.2461 - val_loss: 1261.4106\n",
      "Epoch 271/1000\n",
      "41/41 [==============================] - 0s 205us/step - loss: 2482.0642 - val_loss: 2866.5632\n",
      "Epoch 272/1000\n",
      "41/41 [==============================] - 0s 221us/step - loss: 2367.0815 - val_loss: 1253.9550\n",
      "Epoch 273/1000\n",
      "41/41 [==============================] - 0s 161us/step - loss: 2494.5532 - val_loss: 2614.1821\n",
      "Epoch 274/1000\n",
      "41/41 [==============================] - 0s 132us/step - loss: 2099.1375 - val_loss: 1068.7422\n",
      "Epoch 275/1000\n",
      "41/41 [==============================] - 0s 128us/step - loss: 2434.5671 - val_loss: 2935.8665\n",
      "Epoch 276/1000\n",
      "41/41 [==============================] - 0s 167us/step - loss: 2419.9873 - val_loss: 1781.0671\n",
      "Epoch 277/1000\n",
      "41/41 [==============================] - 0s 151us/step - loss: 2802.1221 - val_loss: 2794.3982\n",
      "Epoch 278/1000\n",
      "41/41 [==============================] - 0s 132us/step - loss: 2530.5369 - val_loss: 1942.2418\n",
      "Epoch 279/1000\n",
      "41/41 [==============================] - 0s 141us/step - loss: 2711.7820 - val_loss: 2666.0586\n",
      "Epoch 280/1000\n",
      "41/41 [==============================] - 0s 164us/step - loss: 2522.3445 - val_loss: 2328.1694\n",
      "Epoch 281/1000\n",
      "41/41 [==============================] - 0s 168us/step - loss: 2951.1633 - val_loss: 2786.5144\n",
      "Epoch 282/1000\n",
      "41/41 [==============================] - 0s 144us/step - loss: 2672.4297 - val_loss: 1865.4240\n",
      "Epoch 283/1000\n",
      "41/41 [==============================] - 0s 141us/step - loss: 2710.4846 - val_loss: 3438.6375\n",
      "Epoch 284/1000\n",
      "41/41 [==============================] - 0s 142us/step - loss: 2793.2788 - val_loss: 2256.1169\n",
      "Epoch 285/1000\n",
      "41/41 [==============================] - 0s 129us/step - loss: 3658.7058 - val_loss: 3223.7500\n",
      "Epoch 286/1000\n",
      "41/41 [==============================] - 0s 145us/step - loss: 2509.0320 - val_loss: 1403.0782\n",
      "Epoch 287/1000\n",
      "41/41 [==============================] - 0s 158us/step - loss: 2774.3191 - val_loss: 2889.3438\n",
      "Epoch 288/1000\n",
      "41/41 [==============================] - 0s 134us/step - loss: 2299.1704 - val_loss: 1333.0903\n",
      "Epoch 289/1000\n",
      "41/41 [==============================] - 0s 130us/step - loss: 2597.7417 - val_loss: 2557.8499\n",
      "Epoch 290/1000\n",
      "41/41 [==============================] - 0s 126us/step - loss: 2096.9443 - val_loss: 1154.2515\n",
      "Epoch 291/1000\n",
      "41/41 [==============================] - 0s 128us/step - loss: 2313.5715 - val_loss: 2508.0063\n",
      "Epoch 292/1000\n",
      "41/41 [==============================] - 0s 132us/step - loss: 2093.8088 - val_loss: 1147.1600\n",
      "Epoch 293/1000\n",
      "41/41 [==============================] - 0s 131us/step - loss: 2217.1741 - val_loss: 2561.8665\n",
      "Epoch 294/1000\n",
      "41/41 [==============================] - 0s 129us/step - loss: 2188.5942 - val_loss: 1204.5538\n",
      "Epoch 295/1000\n",
      "41/41 [==============================] - 0s 138us/step - loss: 2296.0435 - val_loss: 2419.6846\n",
      "Epoch 296/1000\n",
      "41/41 [==============================] - 0s 132us/step - loss: 2080.8933 - val_loss: 1104.2999\n",
      "Epoch 297/1000\n",
      "41/41 [==============================] - 0s 135us/step - loss: 2185.9583 - val_loss: 2559.0317\n",
      "Epoch 298/1000\n",
      "41/41 [==============================] - 0s 174us/step - loss: 2126.2805 - val_loss: 1123.0679\n",
      "Epoch 299/1000\n",
      "41/41 [==============================] - 0s 129us/step - loss: 2358.5874 - val_loss: 2610.7366\n",
      "Epoch 300/1000\n",
      "41/41 [==============================] - 0s 155us/step - loss: 2152.0603 - val_loss: 1219.1532\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 301/1000\n",
      "41/41 [==============================] - 0s 144us/step - loss: 2454.7539 - val_loss: 2603.7588\n",
      "Epoch 302/1000\n",
      "41/41 [==============================] - 0s 152us/step - loss: 2130.6704 - val_loss: 1136.3208\n",
      "Epoch 303/1000\n",
      "41/41 [==============================] - 0s 139us/step - loss: 2408.0254 - val_loss: 2599.2009\n",
      "Epoch 304/1000\n",
      "41/41 [==============================] - 0s 131us/step - loss: 2097.7964 - val_loss: 992.6829\n",
      "Epoch 305/1000\n",
      "41/41 [==============================] - 0s 162us/step - loss: 2335.8416 - val_loss: 2666.9736\n",
      "Epoch 306/1000\n",
      "41/41 [==============================] - 0s 155us/step - loss: 2130.1963 - val_loss: 949.1685\n",
      "Epoch 307/1000\n",
      "41/41 [==============================] - 0s 158us/step - loss: 2330.7957 - val_loss: 2757.1821\n",
      "Epoch 308/1000\n",
      "41/41 [==============================] - 0s 136us/step - loss: 2200.6616 - val_loss: 1194.3400\n",
      "Epoch 309/1000\n",
      "41/41 [==============================] - 0s 134us/step - loss: 2463.9915 - val_loss: 2652.8787\n",
      "Epoch 310/1000\n",
      "41/41 [==============================] - 0s 128us/step - loss: 2220.1072 - val_loss: 1404.2178\n",
      "Epoch 311/1000\n",
      "41/41 [==============================] - 0s 139us/step - loss: 2383.2791 - val_loss: 2307.7412\n",
      "Epoch 312/1000\n",
      "41/41 [==============================] - 0s 124us/step - loss: 2009.3352 - val_loss: 1267.4688\n",
      "Epoch 313/1000\n",
      "41/41 [==============================] - 0s 177us/step - loss: 2126.4917 - val_loss: 2254.8179\n",
      "Epoch 314/1000\n",
      "41/41 [==============================] - 0s 142us/step - loss: 1952.7333 - val_loss: 1165.2155\n",
      "Epoch 315/1000\n",
      "41/41 [==============================] - 0s 141us/step - loss: 2109.2373 - val_loss: 2527.9290\n",
      "Epoch 316/1000\n",
      "41/41 [==============================] - 0s 120us/step - loss: 2094.2957 - val_loss: 1173.8270\n",
      "Epoch 317/1000\n",
      "41/41 [==============================] - 0s 220us/step - loss: 2387.1460 - val_loss: 3249.3018\n",
      "Epoch 318/1000\n",
      "41/41 [==============================] - 0s 138us/step - loss: 2609.2227 - val_loss: 1915.8129\n",
      "Epoch 319/1000\n",
      "41/41 [==============================] - 0s 172us/step - loss: 3170.7913 - val_loss: 3468.1016\n",
      "Epoch 320/1000\n",
      "41/41 [==============================] - 0s 192us/step - loss: 2889.1248 - val_loss: 2043.2423\n",
      "Epoch 321/1000\n",
      "41/41 [==============================] - 0s 187us/step - loss: 3225.0828 - val_loss: 2828.8379\n",
      "Epoch 322/1000\n",
      "41/41 [==============================] - 0s 236us/step - loss: 2310.7842 - val_loss: 1191.8442\n",
      "Epoch 323/1000\n",
      "41/41 [==============================] - 0s 165us/step - loss: 2464.2642 - val_loss: 2731.4868\n",
      "Epoch 324/1000\n",
      "41/41 [==============================] - 0s 171us/step - loss: 2187.7036 - val_loss: 1131.5046\n",
      "Epoch 325/1000\n",
      "41/41 [==============================] - 0s 158us/step - loss: 2479.1113 - val_loss: 2745.3464\n",
      "Epoch 326/1000\n",
      "41/41 [==============================] - 0s 156us/step - loss: 2299.4377 - val_loss: 1181.9659\n",
      "Epoch 327/1000\n",
      "41/41 [==============================] - 0s 177us/step - loss: 2303.3499 - val_loss: 2655.1938\n",
      "Epoch 328/1000\n",
      "41/41 [==============================] - 0s 142us/step - loss: 2250.8369 - val_loss: 1235.1364\n",
      "Epoch 329/1000\n",
      "41/41 [==============================] - 0s 165us/step - loss: 2441.2241 - val_loss: 2556.8970\n",
      "Epoch 330/1000\n",
      "41/41 [==============================] - 0s 84us/step - loss: 2130.3286 - val_loss: 1188.1698\n",
      "Epoch 331/1000\n",
      "41/41 [==============================] - 0s 151us/step - loss: 2318.2219 - val_loss: 2604.3330\n",
      "Epoch 332/1000\n",
      "41/41 [==============================] - 0s 123us/step - loss: 2118.4644 - val_loss: 1155.0679\n",
      "Epoch 333/1000\n",
      "41/41 [==============================] - 0s 129us/step - loss: 2354.5300 - val_loss: 2771.2581\n",
      "Epoch 334/1000\n",
      "41/41 [==============================] - 0s 146us/step - loss: 2221.3413 - val_loss: 1359.2870\n",
      "Epoch 335/1000\n",
      "41/41 [==============================] - 0s 197us/step - loss: 2550.4934 - val_loss: 2525.0217\n",
      "Epoch 336/1000\n",
      "41/41 [==============================] - 0s 136us/step - loss: 2121.8645 - val_loss: 1239.5690\n",
      "Epoch 337/1000\n",
      "41/41 [==============================] - 0s 141us/step - loss: 2327.6724 - val_loss: 2558.2080\n",
      "Epoch 338/1000\n",
      "41/41 [==============================] - 0s 146us/step - loss: 2138.7249 - val_loss: 1233.7249\n",
      "Epoch 339/1000\n",
      "41/41 [==============================] - 0s 147us/step - loss: 2326.4985 - val_loss: 2447.3491\n",
      "Epoch 340/1000\n",
      "41/41 [==============================] - 0s 136us/step - loss: 2030.2372 - val_loss: 1054.4308\n",
      "Epoch 341/1000\n",
      "41/41 [==============================] - 0s 99us/step - loss: 2220.9885 - val_loss: 2651.0837\n",
      "Epoch 342/1000\n",
      "41/41 [==============================] - 0s 105us/step - loss: 2133.8386 - val_loss: 1114.6785\n",
      "Epoch 343/1000\n",
      "41/41 [==============================] - 0s 99us/step - loss: 2327.8711 - val_loss: 2785.6836\n",
      "Epoch 344/1000\n",
      "41/41 [==============================] - 0s 135us/step - loss: 2205.7375 - val_loss: 1091.9690\n",
      "Epoch 345/1000\n",
      "41/41 [==============================] - 0s 151us/step - loss: 2345.3369 - val_loss: 2865.9600\n",
      "Epoch 346/1000\n",
      "41/41 [==============================] - 0s 119us/step - loss: 2222.8831 - val_loss: 1173.4998\n",
      "Epoch 347/1000\n",
      "41/41 [==============================] - 0s 105us/step - loss: 2526.1489 - val_loss: 2918.9280\n",
      "Epoch 348/1000\n",
      "41/41 [==============================] - 0s 119us/step - loss: 2350.3101 - val_loss: 1190.4091\n",
      "Epoch 349/1000\n",
      "41/41 [==============================] - 0s 168us/step - loss: 2424.6489 - val_loss: 2425.3772\n",
      "Epoch 350/1000\n",
      "41/41 [==============================] - 0s 178us/step - loss: 2014.1929 - val_loss: 988.1617\n",
      "Epoch 351/1000\n",
      "41/41 [==============================] - 0s 124us/step - loss: 2170.2639 - val_loss: 2700.1780\n",
      "Epoch 352/1000\n",
      "41/41 [==============================] - 0s 160us/step - loss: 2239.1072 - val_loss: 1407.0293\n",
      "Epoch 353/1000\n",
      "41/41 [==============================] - 0s 102us/step - loss: 2542.6150 - val_loss: 2808.6768\n",
      "Epoch 354/1000\n",
      "41/41 [==============================] - 0s 146us/step - loss: 2387.1208 - val_loss: 1562.8224\n",
      "Epoch 355/1000\n",
      "41/41 [==============================] - 0s 147us/step - loss: 2621.2271 - val_loss: 2370.9006\n",
      "Epoch 356/1000\n",
      "41/41 [==============================] - 0s 133us/step - loss: 2043.1637 - val_loss: 1314.1440\n",
      "Epoch 357/1000\n",
      "41/41 [==============================] - 0s 149us/step - loss: 2297.5049 - val_loss: 2388.1335\n",
      "Epoch 358/1000\n",
      "41/41 [==============================] - 0s 102us/step - loss: 2061.1399 - val_loss: 1433.7035\n",
      "Epoch 359/1000\n",
      "41/41 [==============================] - 0s 195us/step - loss: 2303.0547 - val_loss: 2450.9070\n",
      "Epoch 360/1000\n",
      "41/41 [==============================] - 0s 127us/step - loss: 2088.6367 - val_loss: 1401.9257\n",
      "Epoch 361/1000\n",
      "41/41 [==============================] - 0s 123us/step - loss: 2339.9766 - val_loss: 2846.5120\n",
      "Epoch 362/1000\n",
      "41/41 [==============================] - 0s 186us/step - loss: 2378.9736 - val_loss: 1320.3425\n",
      "Epoch 363/1000\n",
      "41/41 [==============================] - 0s 134us/step - loss: 2489.8904 - val_loss: 2862.3672\n",
      "Epoch 364/1000\n",
      "41/41 [==============================] - 0s 148us/step - loss: 2223.3311 - val_loss: 1121.1075\n",
      "Epoch 365/1000\n",
      "41/41 [==============================] - 0s 112us/step - loss: 2605.0222 - val_loss: 2976.9087\n",
      "Epoch 366/1000\n",
      "41/41 [==============================] - 0s 121us/step - loss: 2335.0134 - val_loss: 1030.9189\n",
      "Epoch 367/1000\n",
      "41/41 [==============================] - 0s 107us/step - loss: 2439.8372 - val_loss: 2630.1064\n",
      "Epoch 368/1000\n",
      "41/41 [==============================] - 0s 137us/step - loss: 2113.1960 - val_loss: 834.2548\n",
      "Epoch 369/1000\n",
      "41/41 [==============================] - 0s 197us/step - loss: 2229.4363 - val_loss: 2608.9851\n",
      "Epoch 370/1000\n",
      "41/41 [==============================] - 0s 112us/step - loss: 2066.3586 - val_loss: 881.3453\n",
      "Epoch 371/1000\n",
      "41/41 [==============================] - 0s 110us/step - loss: 2296.0708 - val_loss: 2728.2747\n",
      "Epoch 372/1000\n",
      "41/41 [==============================] - 0s 121us/step - loss: 2150.9431 - val_loss: 1163.3104\n",
      "Epoch 373/1000\n",
      "41/41 [==============================] - 0s 102us/step - loss: 2409.4277 - val_loss: 2867.3425\n",
      "Epoch 374/1000\n",
      "41/41 [==============================] - 0s 111us/step - loss: 2293.3540 - val_loss: 1262.5060\n",
      "Epoch 375/1000\n",
      "41/41 [==============================] - 0s 96us/step - loss: 2443.4075 - val_loss: 2466.5310\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 376/1000\n",
      "41/41 [==============================] - 0s 136us/step - loss: 2002.3824 - val_loss: 1155.8495\n",
      "Epoch 377/1000\n",
      "41/41 [==============================] - 0s 264us/step - loss: 2227.1694 - val_loss: 2622.3884\n",
      "Epoch 378/1000\n",
      "41/41 [==============================] - 0s 145us/step - loss: 2203.1196 - val_loss: 1535.1268\n",
      "Epoch 379/1000\n",
      "41/41 [==============================] - 0s 110us/step - loss: 2466.9158 - val_loss: 2410.1306\n",
      "Epoch 380/1000\n",
      "41/41 [==============================] - 0s 98us/step - loss: 2194.4099 - val_loss: 1519.9329\n",
      "Epoch 381/1000\n",
      "41/41 [==============================] - 0s 102us/step - loss: 2319.0488 - val_loss: 2425.6567\n",
      "Epoch 382/1000\n",
      "41/41 [==============================] - 0s 130us/step - loss: 2109.8606 - val_loss: 1322.4441\n",
      "Epoch 383/1000\n",
      "41/41 [==============================] - 0s 108us/step - loss: 2320.5959 - val_loss: 2625.2373\n",
      "Epoch 384/1000\n",
      "41/41 [==============================] - 0s 119us/step - loss: 2146.6489 - val_loss: 1107.9523\n",
      "Epoch 385/1000\n",
      "41/41 [==============================] - 0s 176us/step - loss: 2378.3237 - val_loss: 2885.0386\n",
      "Epoch 386/1000\n",
      "41/41 [==============================] - 0s 151us/step - loss: 2268.0957 - val_loss: 1010.8492\n",
      "Epoch 387/1000\n",
      "41/41 [==============================] - 0s 136us/step - loss: 2517.6926 - val_loss: 2728.0271\n",
      "Epoch 388/1000\n",
      "41/41 [==============================] - 0s 107us/step - loss: 2170.0808 - val_loss: 1059.6971\n",
      "Epoch 389/1000\n",
      "41/41 [==============================] - 0s 100us/step - loss: 2482.4861 - val_loss: 2700.7375\n",
      "Epoch 390/1000\n",
      "41/41 [==============================] - 0s 117us/step - loss: 2171.2954 - val_loss: 1140.6907\n",
      "Epoch 391/1000\n",
      "41/41 [==============================] - 0s 113us/step - loss: 2355.0635 - val_loss: 2589.4849\n",
      "Epoch 392/1000\n",
      "41/41 [==============================] - 0s 113us/step - loss: 2147.4631 - val_loss: 1242.1619\n",
      "Epoch 393/1000\n",
      "41/41 [==============================] - 0s 131us/step - loss: 2277.0774 - val_loss: 2610.3076\n",
      "Epoch 394/1000\n",
      "41/41 [==============================] - 0s 170us/step - loss: 2161.8704 - val_loss: 1226.1805\n",
      "Epoch 395/1000\n",
      "41/41 [==============================] - 0s 118us/step - loss: 2282.5024 - val_loss: 2504.1208\n",
      "Epoch 396/1000\n",
      "41/41 [==============================] - 0s 130us/step - loss: 2010.9586 - val_loss: 972.5370\n",
      "Epoch 397/1000\n",
      "41/41 [==============================] - 0s 135us/step - loss: 2167.9158 - val_loss: 2933.9475\n",
      "Epoch 398/1000\n",
      "41/41 [==============================] - 0s 176us/step - loss: 2238.8845 - val_loss: 1258.3784\n",
      "Epoch 399/1000\n",
      "41/41 [==============================] - 0s 142us/step - loss: 2596.9465 - val_loss: 2854.9529\n",
      "Epoch 400/1000\n",
      "41/41 [==============================] - 0s 146us/step - loss: 2287.9304 - val_loss: 1371.1781\n",
      "Epoch 401/1000\n",
      "41/41 [==============================] - 0s 110us/step - loss: 2505.6477 - val_loss: 2396.3252\n",
      "Epoch 402/1000\n",
      "41/41 [==============================] - 0s 132us/step - loss: 2057.2578 - val_loss: 1410.6779\n",
      "Epoch 403/1000\n",
      "41/41 [==============================] - 0s 167us/step - loss: 2254.8479 - val_loss: 2211.2327\n",
      "Epoch 404/1000\n",
      "41/41 [==============================] - 0s 117us/step - loss: 1989.7789 - val_loss: 1509.5763\n",
      "Epoch 405/1000\n",
      "41/41 [==============================] - 0s 113us/step - loss: 2169.7522 - val_loss: 2225.5823\n",
      "Epoch 406/1000\n",
      "41/41 [==============================] - 0s 130us/step - loss: 2035.4575 - val_loss: 1421.4939\n",
      "Epoch 407/1000\n",
      "41/41 [==============================] - 0s 124us/step - loss: 2193.2268 - val_loss: 2639.5042\n",
      "Epoch 408/1000\n",
      "41/41 [==============================] - 0s 169us/step - loss: 2212.9282 - val_loss: 1142.6772\n",
      "Epoch 409/1000\n",
      "41/41 [==============================] - 0s 152us/step - loss: 2337.9189 - val_loss: 3010.0862\n",
      "Epoch 410/1000\n",
      "41/41 [==============================] - 0s 117us/step - loss: 2377.0327 - val_loss: 1220.5278\n",
      "Epoch 411/1000\n",
      "41/41 [==============================] - 0s 116us/step - loss: 2617.4097 - val_loss: 2853.5969\n",
      "Epoch 412/1000\n",
      "41/41 [==============================] - 0s 157us/step - loss: 2231.8408 - val_loss: 1020.8755\n",
      "Epoch 413/1000\n",
      "41/41 [==============================] - 0s 147us/step - loss: 2480.4434 - val_loss: 2720.8113\n",
      "Epoch 414/1000\n",
      "41/41 [==============================] - 0s 101us/step - loss: 2180.9094 - val_loss: 1170.0238\n",
      "Epoch 415/1000\n",
      "41/41 [==============================] - 0s 85us/step - loss: 2413.5608 - val_loss: 2574.3376\n",
      "Epoch 416/1000\n",
      "41/41 [==============================] - 0s 137us/step - loss: 2138.9424 - val_loss: 1181.0696\n",
      "Epoch 417/1000\n",
      "41/41 [==============================] - 0s 122us/step - loss: 2321.6934 - val_loss: 2481.0654\n",
      "Epoch 418/1000\n",
      "41/41 [==============================] - 0s 148us/step - loss: 2034.6019 - val_loss: 1075.0880\n",
      "Epoch 419/1000\n",
      "41/41 [==============================] - 0s 92us/step - loss: 2264.2253 - val_loss: 2699.6760\n",
      "Epoch 420/1000\n",
      "41/41 [==============================] - 0s 117us/step - loss: 2149.6465 - val_loss: 1135.9163\n",
      "Epoch 421/1000\n",
      "41/41 [==============================] - 0s 124us/step - loss: 2351.1165 - val_loss: 2542.2949\n",
      "Epoch 422/1000\n",
      "41/41 [==============================] - 0s 118us/step - loss: 2055.4641 - val_loss: 1081.8149\n",
      "Epoch 423/1000\n",
      "41/41 [==============================] - 0s 161us/step - loss: 2253.2209 - val_loss: 2589.0559\n",
      "Epoch 424/1000\n",
      "41/41 [==============================] - 0s 103us/step - loss: 2070.3879 - val_loss: 1117.8894\n",
      "Epoch 425/1000\n",
      "41/41 [==============================] - 0s 108us/step - loss: 2317.8472 - val_loss: 2676.5356\n",
      "Epoch 426/1000\n",
      "41/41 [==============================] - 0s 123us/step - loss: 2211.0017 - val_loss: 1224.8950\n",
      "Epoch 427/1000\n",
      "41/41 [==============================] - 0s 88us/step - loss: 2371.2417 - val_loss: 2594.4336\n",
      "Epoch 428/1000\n",
      "41/41 [==============================] - 0s 117us/step - loss: 2161.8545 - val_loss: 1055.5809\n",
      "Epoch 429/1000\n",
      "41/41 [==============================] - 0s 162us/step - loss: 2274.7148 - val_loss: 2642.0625\n",
      "Epoch 430/1000\n",
      "41/41 [==============================] - 0s 104us/step - loss: 2170.6978 - val_loss: 1009.9384\n",
      "Epoch 431/1000\n",
      "41/41 [==============================] - 0s 89us/step - loss: 2298.1792 - val_loss: 2565.8000\n",
      "Epoch 432/1000\n",
      "41/41 [==============================] - 0s 113us/step - loss: 2142.9292 - val_loss: 1068.1819\n",
      "Epoch 433/1000\n",
      "41/41 [==============================] - 0s 110us/step - loss: 2343.1863 - val_loss: 2915.7742\n",
      "Epoch 434/1000\n",
      "41/41 [==============================] - 0s 94us/step - loss: 2367.0798 - val_loss: 1440.7859\n",
      "Epoch 435/1000\n",
      "41/41 [==============================] - 0s 130us/step - loss: 2659.9097 - val_loss: 2599.5183\n",
      "Epoch 436/1000\n",
      "41/41 [==============================] - 0s 182us/step - loss: 2121.3979 - val_loss: 1191.7126\n",
      "Epoch 437/1000\n",
      "41/41 [==============================] - 0s 117us/step - loss: 2384.6055 - val_loss: 2557.9136\n",
      "Epoch 438/1000\n",
      "41/41 [==============================] - 0s 121us/step - loss: 2049.9014 - val_loss: 1061.6342\n",
      "Epoch 439/1000\n",
      "41/41 [==============================] - 0s 94us/step - loss: 2220.4751 - val_loss: 2561.9656\n",
      "Epoch 440/1000\n",
      "41/41 [==============================] - 0s 125us/step - loss: 2063.6533 - val_loss: 1063.5641\n",
      "Epoch 441/1000\n",
      "41/41 [==============================] - 0s 119us/step - loss: 2220.7349 - val_loss: 2514.8291\n",
      "Epoch 442/1000\n",
      "41/41 [==============================] - 0s 105us/step - loss: 2063.8350 - val_loss: 1036.0167\n",
      "Epoch 443/1000\n",
      "41/41 [==============================] - 0s 113us/step - loss: 2163.9121 - val_loss: 2499.9968\n",
      "Epoch 444/1000\n",
      "41/41 [==============================] - 0s 98us/step - loss: 2029.1881 - val_loss: 995.2781\n",
      "Epoch 445/1000\n",
      "41/41 [==============================] - 0s 149us/step - loss: 2183.6655 - val_loss: 2732.9189\n",
      "Epoch 446/1000\n",
      "41/41 [==============================] - 0s 127us/step - loss: 2122.6299 - val_loss: 1040.8019\n",
      "Epoch 447/1000\n",
      "41/41 [==============================] - 0s 113us/step - loss: 2395.6501 - val_loss: 2857.0142\n",
      "Epoch 448/1000\n",
      "41/41 [==============================] - 0s 90us/step - loss: 2215.3623 - val_loss: 1141.8645\n",
      "Epoch 449/1000\n",
      "41/41 [==============================] - 0s 120us/step - loss: 2512.2729 - val_loss: 2844.2341\n",
      "Epoch 450/1000\n",
      "41/41 [==============================] - 0s 129us/step - loss: 2225.9832 - val_loss: 1163.4087\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 451/1000\n",
      "41/41 [==============================] - 0s 118us/step - loss: 2471.6807 - val_loss: 2581.0042\n",
      "Epoch 452/1000\n",
      "41/41 [==============================] - 0s 141us/step - loss: 2126.4424 - val_loss: 1078.9413\n",
      "Epoch 453/1000\n",
      "41/41 [==============================] - 0s 133us/step - loss: 2273.2529 - val_loss: 2379.8240\n",
      "Epoch 454/1000\n",
      "41/41 [==============================] - 0s 150us/step - loss: 2005.3267 - val_loss: 1049.7903\n",
      "Epoch 455/1000\n",
      "41/41 [==============================] - 0s 117us/step - loss: 2174.7834 - val_loss: 2455.9788\n",
      "Epoch 456/1000\n",
      "41/41 [==============================] - 0s 119us/step - loss: 2053.4858 - val_loss: 1259.1678\n",
      "Epoch 457/1000\n",
      "41/41 [==============================] - 0s 110us/step - loss: 2266.0916 - val_loss: 2690.5615\n",
      "Epoch 458/1000\n",
      "41/41 [==============================] - 0s 116us/step - loss: 2215.1125 - val_loss: 1321.4080\n",
      "Epoch 459/1000\n",
      "41/41 [==============================] - 0s 143us/step - loss: 2413.1790 - val_loss: 2739.2971\n",
      "Epoch 460/1000\n",
      "41/41 [==============================] - 0s 105us/step - loss: 2133.3071 - val_loss: 1158.1364\n",
      "Epoch 461/1000\n",
      "41/41 [==============================] - 0s 150us/step - loss: 2430.9089 - val_loss: 2772.6775\n",
      "Epoch 462/1000\n",
      "41/41 [==============================] - 0s 110us/step - loss: 2200.4666 - val_loss: 1101.4684\n",
      "Epoch 463/1000\n",
      "41/41 [==============================] - 0s 131us/step - loss: 2296.9761 - val_loss: 2770.7996\n",
      "Epoch 464/1000\n",
      "41/41 [==============================] - 0s 172us/step - loss: 2231.5549 - val_loss: 1174.8076\n",
      "Epoch 465/1000\n",
      "41/41 [==============================] - 0s 145us/step - loss: 2293.1353 - val_loss: 2544.2920\n",
      "Epoch 466/1000\n",
      "41/41 [==============================] - 0s 147us/step - loss: 2144.5496 - val_loss: 1465.2899\n",
      "Epoch 467/1000\n",
      "41/41 [==============================] - 0s 154us/step - loss: 2334.2534 - val_loss: 2339.4004\n",
      "Epoch 468/1000\n",
      "41/41 [==============================] - 0s 133us/step - loss: 2086.9900 - val_loss: 1448.6132\n",
      "Epoch 469/1000\n",
      "41/41 [==============================] - 0s 179us/step - loss: 2193.3706 - val_loss: 2177.0298\n",
      "Epoch 470/1000\n",
      "41/41 [==============================] - 0s 129us/step - loss: 2065.4319 - val_loss: 1562.9634\n",
      "Epoch 471/1000\n",
      "41/41 [==============================] - 0s 149us/step - loss: 2083.7104 - val_loss: 1927.5093\n",
      "Epoch 472/1000\n",
      "41/41 [==============================] - 0s 156us/step - loss: 1969.3611 - val_loss: 1567.9357\n",
      "Epoch 473/1000\n",
      "41/41 [==============================] - 0s 97us/step - loss: 1979.2014 - val_loss: 2155.3401\n",
      "Epoch 474/1000\n",
      "41/41 [==============================] - 0s 92us/step - loss: 1976.0167 - val_loss: 1258.1210\n",
      "Epoch 475/1000\n",
      "41/41 [==============================] - 0s 173us/step - loss: 2229.5198 - val_loss: 3261.7358\n",
      "Epoch 476/1000\n",
      "41/41 [==============================] - 0s 107us/step - loss: 2494.3330 - val_loss: 1298.3981\n",
      "Epoch 477/1000\n",
      "41/41 [==============================] - 0s 122us/step - loss: 2774.1104 - val_loss: 2863.0010\n",
      "Epoch 478/1000\n",
      "41/41 [==============================] - 0s 106us/step - loss: 2224.9724 - val_loss: 1168.1046\n",
      "Epoch 479/1000\n",
      "41/41 [==============================] - 0s 90us/step - loss: 2562.7327 - val_loss: 2892.5640\n",
      "Epoch 480/1000\n",
      "41/41 [==============================] - 0s 150us/step - loss: 2256.5095 - val_loss: 1287.7255\n",
      "Epoch 481/1000\n",
      "41/41 [==============================] - 0s 109us/step - loss: 2537.3311 - val_loss: 2863.7615\n",
      "Epoch 482/1000\n",
      "41/41 [==============================] - 0s 153us/step - loss: 2271.7515 - val_loss: 1452.1349\n",
      "Epoch 483/1000\n",
      "41/41 [==============================] - 0s 122us/step - loss: 2573.3193 - val_loss: 3296.3779\n",
      "Epoch 484/1000\n",
      "41/41 [==============================] - 0s 218us/step - loss: 2676.1021 - val_loss: 1521.4965\n",
      "Epoch 485/1000\n",
      "41/41 [==============================] - 0s 106us/step - loss: 2709.7358 - val_loss: 2304.1365\n",
      "Epoch 486/1000\n",
      "41/41 [==============================] - 0s 121us/step - loss: 1881.4846 - val_loss: 995.4753\n",
      "Epoch 487/1000\n",
      "41/41 [==============================] - 0s 141us/step - loss: 2048.4927 - val_loss: 2728.1982\n",
      "Epoch 488/1000\n",
      "41/41 [==============================] - 0s 113us/step - loss: 2158.7954 - val_loss: 1041.3595\n",
      "Epoch 489/1000\n",
      "41/41 [==============================] - 0s 109us/step - loss: 2311.8782 - val_loss: 2510.1382\n",
      "Epoch 490/1000\n",
      "41/41 [==============================] - 0s 161us/step - loss: 2042.1069 - val_loss: 943.5479\n",
      "Epoch 491/1000\n",
      "41/41 [==============================] - 0s 116us/step - loss: 2222.1138 - val_loss: 2845.6355\n",
      "Epoch 492/1000\n",
      "41/41 [==============================] - 0s 132us/step - loss: 2266.1323 - val_loss: 1261.9951\n",
      "Epoch 493/1000\n",
      "41/41 [==============================] - 0s 105us/step - loss: 2497.0244 - val_loss: 2749.6462\n",
      "Epoch 494/1000\n",
      "41/41 [==============================] - 0s 174us/step - loss: 2242.6885 - val_loss: 1105.6365\n",
      "Epoch 495/1000\n",
      "41/41 [==============================] - 0s 106us/step - loss: 2264.3821 - val_loss: 2410.1875\n",
      "Epoch 496/1000\n",
      "41/41 [==============================] - 0s 180us/step - loss: 1995.7205 - val_loss: 1061.5286\n",
      "Epoch 497/1000\n",
      "41/41 [==============================] - 0s 132us/step - loss: 2085.7722 - val_loss: 2361.5527\n",
      "Epoch 498/1000\n",
      "41/41 [==============================] - 0s 138us/step - loss: 2031.8787 - val_loss: 1267.0856\n",
      "Epoch 499/1000\n",
      "41/41 [==============================] - 0s 106us/step - loss: 2152.6887 - val_loss: 2225.0251\n",
      "Epoch 500/1000\n",
      "41/41 [==============================] - 0s 130us/step - loss: 2006.8668 - val_loss: 1302.0668\n",
      "Epoch 501/1000\n",
      "41/41 [==============================] - 0s 113us/step - loss: 2134.0630 - val_loss: 2491.8843\n",
      "Epoch 502/1000\n",
      "41/41 [==============================] - 0s 138us/step - loss: 2137.9805 - val_loss: 1342.8641\n",
      "Epoch 503/1000\n",
      "41/41 [==============================] - 0s 169us/step - loss: 2418.6052 - val_loss: 2923.2852\n",
      "Epoch 504/1000\n",
      "41/41 [==============================] - 0s 158us/step - loss: 2262.2952 - val_loss: 1136.1758\n",
      "Epoch 505/1000\n",
      "41/41 [==============================] - 0s 135us/step - loss: 2562.0525 - val_loss: 2816.0352\n",
      "Epoch 506/1000\n",
      "41/41 [==============================] - 0s 92us/step - loss: 2194.7056 - val_loss: 946.6949\n",
      "Epoch 507/1000\n",
      "41/41 [==============================] - 0s 90us/step - loss: 2410.4316 - val_loss: 2980.8499\n",
      "Epoch 508/1000\n",
      "41/41 [==============================] - 0s 166us/step - loss: 2298.8242 - val_loss: 1072.9376\n",
      "Epoch 509/1000\n",
      "41/41 [==============================] - 0s 142us/step - loss: 2455.2747 - val_loss: 2961.0396\n",
      "Epoch 510/1000\n",
      "41/41 [==============================] - 0s 139us/step - loss: 2345.5500 - val_loss: 1278.6930\n",
      "Epoch 511/1000\n",
      "41/41 [==============================] - 0s 129us/step - loss: 2540.4697 - val_loss: 2497.9944\n",
      "Epoch 512/1000\n",
      "41/41 [==============================] - 0s 112us/step - loss: 2015.3628 - val_loss: 1031.5015\n",
      "Epoch 513/1000\n",
      "41/41 [==============================] - 0s 118us/step - loss: 2093.5237 - val_loss: 2403.1350\n",
      "Epoch 514/1000\n",
      "41/41 [==============================] - 0s 129us/step - loss: 1975.9554 - val_loss: 1137.7955\n",
      "Epoch 515/1000\n",
      "41/41 [==============================] - 0s 105us/step - loss: 2049.7114 - val_loss: 2356.1807\n",
      "Epoch 516/1000\n",
      "41/41 [==============================] - 0s 132us/step - loss: 1977.8180 - val_loss: 1229.0771\n",
      "Epoch 517/1000\n",
      "41/41 [==============================] - 0s 183us/step - loss: 2094.4307 - val_loss: 2544.4993\n",
      "Epoch 518/1000\n",
      "41/41 [==============================] - 0s 81us/step - loss: 2100.8020 - val_loss: 1409.6445\n",
      "Epoch 519/1000\n",
      "41/41 [==============================] - 0s 127us/step - loss: 2415.1365 - val_loss: 2784.6663\n",
      "Epoch 520/1000\n",
      "41/41 [==============================] - 0s 110us/step - loss: 2207.9819 - val_loss: 1272.9679\n",
      "Epoch 521/1000\n",
      "41/41 [==============================] - 0s 116us/step - loss: 2504.3542 - val_loss: 2684.4189\n",
      "Epoch 522/1000\n",
      "41/41 [==============================] - 0s 104us/step - loss: 2119.3672 - val_loss: 987.6285\n",
      "Epoch 523/1000\n",
      "41/41 [==============================] - 0s 203us/step - loss: 2354.0854 - val_loss: 2771.5117\n",
      "Epoch 524/1000\n",
      "41/41 [==============================] - 0s 127us/step - loss: 2159.8743 - val_loss: 877.8625\n",
      "Epoch 525/1000\n",
      "41/41 [==============================] - 0s 113us/step - loss: 2284.8357 - val_loss: 2472.3372\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 526/1000\n",
      "41/41 [==============================] - 0s 121us/step - loss: 2052.4517 - val_loss: 986.9119\n",
      "Epoch 527/1000\n",
      "41/41 [==============================] - 0s 121us/step - loss: 2163.1428 - val_loss: 2476.2627\n",
      "Epoch 528/1000\n",
      "41/41 [==============================] - 0s 122us/step - loss: 2062.0422 - val_loss: 1089.6337\n",
      "Epoch 529/1000\n",
      "41/41 [==============================] - 0s 140us/step - loss: 2237.9294 - val_loss: 2839.0920\n",
      "Epoch 530/1000\n",
      "41/41 [==============================] - 0s 114us/step - loss: 2282.4041 - val_loss: 1465.8134\n",
      "Epoch 531/1000\n",
      "41/41 [==============================] - 0s 88us/step - loss: 2689.2693 - val_loss: 3094.4573\n",
      "Epoch 532/1000\n",
      "41/41 [==============================] - 0s 130us/step - loss: 2500.1809 - val_loss: 1550.2316\n",
      "Epoch 533/1000\n",
      "41/41 [==============================] - 0s 139us/step - loss: 2694.0344 - val_loss: 2400.9043\n",
      "Epoch 534/1000\n",
      "41/41 [==============================] - 0s 139us/step - loss: 2037.6641 - val_loss: 1355.5886\n",
      "Epoch 535/1000\n",
      "41/41 [==============================] - 0s 115us/step - loss: 2238.4092 - val_loss: 2155.8127\n",
      "Epoch 536/1000\n",
      "41/41 [==============================] - 0s 128us/step - loss: 2009.8091 - val_loss: 1528.7365\n",
      "Epoch 537/1000\n",
      "41/41 [==============================] - 0s 115us/step - loss: 2163.2812 - val_loss: 2035.2661\n",
      "Epoch 538/1000\n",
      "41/41 [==============================] - 0s 110us/step - loss: 2045.0051 - val_loss: 1512.5519\n",
      "Epoch 539/1000\n",
      "41/41 [==============================] - 0s 182us/step - loss: 2102.4727 - val_loss: 2319.1680\n",
      "Epoch 540/1000\n",
      "41/41 [==============================] - 0s 199us/step - loss: 2127.6462 - val_loss: 1302.0619\n",
      "Epoch 541/1000\n",
      "41/41 [==============================] - 0s 186us/step - loss: 2216.9465 - val_loss: 2706.3440\n",
      "Epoch 542/1000\n",
      "41/41 [==============================] - 0s 114us/step - loss: 2205.6616 - val_loss: 1044.9865\n",
      "Epoch 543/1000\n",
      "41/41 [==============================] - 0s 158us/step - loss: 2356.3110 - val_loss: 2922.8643\n",
      "Epoch 544/1000\n",
      "41/41 [==============================] - 0s 95us/step - loss: 2240.1658 - val_loss: 1177.4841\n",
      "Epoch 545/1000\n",
      "41/41 [==============================] - 0s 124us/step - loss: 2523.5093 - val_loss: 2793.9648\n",
      "Epoch 546/1000\n",
      "41/41 [==============================] - 0s 224us/step - loss: 2212.2227 - val_loss: 1241.0477\n",
      "Epoch 547/1000\n",
      "41/41 [==============================] - 0s 144us/step - loss: 2433.5288 - val_loss: 2643.2112\n",
      "Epoch 548/1000\n",
      "41/41 [==============================] - 0s 181us/step - loss: 2078.1340 - val_loss: 1052.6012\n",
      "Epoch 549/1000\n",
      "41/41 [==============================] - 0s 116us/step - loss: 2302.8267 - val_loss: 2635.4836\n",
      "Epoch 550/1000\n",
      "41/41 [==============================] - 0s 139us/step - loss: 2039.0991 - val_loss: 867.9578\n",
      "Epoch 551/1000\n",
      "41/41 [==============================] - 0s 174us/step - loss: 2224.8643 - val_loss: 2712.8713\n",
      "Epoch 552/1000\n",
      "41/41 [==============================] - 0s 155us/step - loss: 2092.0281 - val_loss: 812.8746\n",
      "Epoch 553/1000\n",
      "41/41 [==============================] - 0s 236us/step - loss: 2268.5693 - val_loss: 2580.2998\n",
      "Epoch 554/1000\n",
      "41/41 [==============================] - 0s 192us/step - loss: 2103.3054 - val_loss: 1023.4554\n",
      "Epoch 555/1000\n",
      "41/41 [==============================] - 0s 168us/step - loss: 2238.5808 - val_loss: 2444.9695\n",
      "Epoch 556/1000\n",
      "41/41 [==============================] - 0s 207us/step - loss: 2088.3113 - val_loss: 1059.9464\n",
      "Epoch 557/1000\n",
      "41/41 [==============================] - 0s 192us/step - loss: 2192.1887 - val_loss: 2679.9094\n",
      "Epoch 558/1000\n",
      "41/41 [==============================] - 0s 243us/step - loss: 2158.4268 - val_loss: 1228.5499\n",
      "Epoch 559/1000\n",
      "41/41 [==============================] - 0s 97us/step - loss: 2509.3271 - val_loss: 2843.3838\n",
      "Epoch 560/1000\n",
      "41/41 [==============================] - 0s 172us/step - loss: 2215.7725 - val_loss: 1105.6156\n",
      "Epoch 561/1000\n",
      "41/41 [==============================] - 0s 152us/step - loss: 2386.2334 - val_loss: 2564.9373\n",
      "Epoch 562/1000\n",
      "41/41 [==============================] - 0s 135us/step - loss: 2057.0122 - val_loss: 1121.7222\n",
      "Epoch 563/1000\n",
      "41/41 [==============================] - 0s 148us/step - loss: 2244.3945 - val_loss: 2643.5977\n",
      "Epoch 564/1000\n",
      "41/41 [==============================] - 0s 136us/step - loss: 2108.7322 - val_loss: 1240.7657\n",
      "Epoch 565/1000\n",
      "41/41 [==============================] - 0s 210us/step - loss: 2290.9121 - val_loss: 2567.4951\n",
      "Epoch 566/1000\n",
      "41/41 [==============================] - 0s 118us/step - loss: 2191.9363 - val_loss: 1368.9757\n",
      "Epoch 567/1000\n",
      "41/41 [==============================] - 0s 160us/step - loss: 2190.4031 - val_loss: 2379.9744\n",
      "Epoch 568/1000\n",
      "41/41 [==============================] - 0s 195us/step - loss: 1976.5139 - val_loss: 1152.2527\n",
      "Epoch 569/1000\n",
      "41/41 [==============================] - 0s 142us/step - loss: 2116.9810 - val_loss: 2662.1992\n",
      "Epoch 570/1000\n",
      "41/41 [==============================] - 0s 96us/step - loss: 2108.1450 - val_loss: 1076.9022\n",
      "Epoch 571/1000\n",
      "41/41 [==============================] - 0s 156us/step - loss: 2286.8430 - val_loss: 2700.9946\n",
      "Epoch 572/1000\n",
      "41/41 [==============================] - 0s 130us/step - loss: 2096.6636 - val_loss: 1060.3945\n",
      "Epoch 573/1000\n",
      "41/41 [==============================] - 0s 192us/step - loss: 2413.0229 - val_loss: 2962.7502\n",
      "Epoch 574/1000\n",
      "41/41 [==============================] - 0s 99us/step - loss: 2266.3320 - val_loss: 1212.2816\n",
      "Epoch 575/1000\n",
      "41/41 [==============================] - 0s 142us/step - loss: 2674.5396 - val_loss: 2799.6404\n",
      "Epoch 576/1000\n",
      "41/41 [==============================] - 0s 144us/step - loss: 2244.2998 - val_loss: 1121.7710\n",
      "Epoch 577/1000\n",
      "41/41 [==============================] - 0s 115us/step - loss: 2317.6489 - val_loss: 2822.1140\n",
      "Epoch 578/1000\n",
      "41/41 [==============================] - 0s 126us/step - loss: 2304.1426 - val_loss: 1139.6157\n",
      "Epoch 579/1000\n",
      "41/41 [==============================] - 0s 177us/step - loss: 2275.5168 - val_loss: 2323.2153\n",
      "Epoch 580/1000\n",
      "41/41 [==============================] - 0s 137us/step - loss: 1997.3573 - val_loss: 1189.6893\n",
      "Epoch 581/1000\n",
      "41/41 [==============================] - 0s 122us/step - loss: 2060.7261 - val_loss: 2056.1575\n",
      "Epoch 582/1000\n",
      "41/41 [==============================] - 0s 166us/step - loss: 1981.8920 - val_loss: 1473.6925\n",
      "Epoch 583/1000\n",
      "41/41 [==============================] - 0s 103us/step - loss: 1935.7389 - val_loss: 1603.9176\n",
      "Epoch 584/1000\n",
      "41/41 [==============================] - 0s 122us/step - loss: 1890.1057 - val_loss: 2019.6313\n",
      "Epoch 585/1000\n",
      "41/41 [==============================] - 0s 119us/step - loss: 1921.5284 - val_loss: 1160.0139\n",
      "Epoch 586/1000\n",
      "41/41 [==============================] - 0s 139us/step - loss: 2182.4395 - val_loss: 3116.5000\n",
      "Epoch 587/1000\n",
      "41/41 [==============================] - 0s 132us/step - loss: 2414.3901 - val_loss: 1268.6060\n",
      "Epoch 588/1000\n",
      "41/41 [==============================] - 0s 142us/step - loss: 2650.5837 - val_loss: 2766.7236\n",
      "Epoch 589/1000\n",
      "41/41 [==============================] - 0s 99us/step - loss: 2155.3679 - val_loss: 1140.8457\n",
      "Epoch 590/1000\n",
      "41/41 [==============================] - 0s 104us/step - loss: 2470.8928 - val_loss: 2829.6501\n",
      "Epoch 591/1000\n",
      "41/41 [==============================] - 0s 170us/step - loss: 2218.0027 - val_loss: 1157.9198\n",
      "Epoch 592/1000\n",
      "41/41 [==============================] - 0s 120us/step - loss: 2364.0640 - val_loss: 2595.5740\n",
      "Epoch 593/1000\n",
      "41/41 [==============================] - 0s 98us/step - loss: 2067.0522 - val_loss: 1172.3026\n",
      "Epoch 594/1000\n",
      "41/41 [==============================] - 0s 122us/step - loss: 2279.7842 - val_loss: 2508.6572\n",
      "Epoch 595/1000\n",
      "41/41 [==============================] - 0s 115us/step - loss: 2042.8705 - val_loss: 1165.9471\n",
      "Epoch 596/1000\n",
      "41/41 [==============================] - 0s 121us/step - loss: 2136.8911 - val_loss: 2422.3330\n",
      "Epoch 597/1000\n",
      "41/41 [==============================] - 0s 124us/step - loss: 1957.8950 - val_loss: 1002.9387\n",
      "Epoch 598/1000\n",
      "41/41 [==============================] - 0s 106us/step - loss: 2096.8423 - val_loss: 2724.4717\n",
      "Epoch 599/1000\n",
      "41/41 [==============================] - 0s 104us/step - loss: 2124.1731 - val_loss: 949.2566\n",
      "Epoch 600/1000\n",
      "41/41 [==============================] - 0s 117us/step - loss: 2357.3772 - val_loss: 2904.8955\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 601/1000\n",
      "41/41 [==============================] - 0s 113us/step - loss: 2306.7065 - val_loss: 1315.8140\n",
      "Epoch 602/1000\n",
      "41/41 [==============================] - 0s 125us/step - loss: 2569.3616 - val_loss: 2536.2942\n",
      "Epoch 603/1000\n",
      "41/41 [==============================] - 0s 97us/step - loss: 2066.4451 - val_loss: 1034.1633\n",
      "Epoch 604/1000\n",
      "41/41 [==============================] - 0s 115us/step - loss: 2246.1926 - val_loss: 2653.2151\n",
      "Epoch 605/1000\n",
      "41/41 [==============================] - 0s 123us/step - loss: 2103.1370 - val_loss: 1021.8853\n",
      "Epoch 606/1000\n",
      "41/41 [==============================] - 0s 111us/step - loss: 2256.1421 - val_loss: 2586.4592\n",
      "Epoch 607/1000\n",
      "41/41 [==============================] - 0s 182us/step - loss: 2050.0967 - val_loss: 1073.5132\n",
      "Epoch 608/1000\n",
      "41/41 [==============================] - 0s 121us/step - loss: 2255.0623 - val_loss: 2584.1604\n",
      "Epoch 609/1000\n",
      "41/41 [==============================] - 0s 133us/step - loss: 2057.4980 - val_loss: 1101.3514\n",
      "Epoch 610/1000\n",
      "41/41 [==============================] - 0s 178us/step - loss: 2211.4739 - val_loss: 2596.6860\n",
      "Epoch 611/1000\n",
      "41/41 [==============================] - 0s 153us/step - loss: 2044.1235 - val_loss: 1060.5065\n",
      "Epoch 612/1000\n",
      "41/41 [==============================] - 0s 99us/step - loss: 2285.7244 - val_loss: 2638.3672\n",
      "Epoch 613/1000\n",
      "41/41 [==============================] - 0s 111us/step - loss: 2073.9409 - val_loss: 1068.4291\n",
      "Epoch 614/1000\n",
      "41/41 [==============================] - 0s 124us/step - loss: 2322.3120 - val_loss: 2633.6318\n",
      "Epoch 615/1000\n",
      "41/41 [==============================] - 0s 139us/step - loss: 2091.1484 - val_loss: 1140.9603\n",
      "Epoch 616/1000\n",
      "41/41 [==============================] - 0s 120us/step - loss: 2312.2295 - val_loss: 2614.7571\n",
      "Epoch 617/1000\n",
      "41/41 [==============================] - 0s 214us/step - loss: 2075.4407 - val_loss: 1124.7719\n",
      "Epoch 618/1000\n",
      "41/41 [==============================] - 0s 136us/step - loss: 2247.0212 - val_loss: 2580.5125\n",
      "Epoch 619/1000\n",
      "41/41 [==============================] - 0s 166us/step - loss: 2051.2617 - val_loss: 1061.3945\n",
      "Epoch 620/1000\n",
      "41/41 [==============================] - 0s 98us/step - loss: 2166.3577 - val_loss: 2684.0037\n",
      "Epoch 621/1000\n",
      "41/41 [==============================] - 0s 126us/step - loss: 2064.1355 - val_loss: 952.2296\n",
      "Epoch 622/1000\n",
      "41/41 [==============================] - 0s 166us/step - loss: 2238.0964 - val_loss: 2666.7834\n",
      "Epoch 623/1000\n",
      "41/41 [==============================] - 0s 174us/step - loss: 2151.9409 - val_loss: 1102.6445\n",
      "Epoch 624/1000\n",
      "41/41 [==============================] - 0s 137us/step - loss: 2257.0469 - val_loss: 2559.3513\n",
      "Epoch 625/1000\n",
      "41/41 [==============================] - 0s 142us/step - loss: 2137.1431 - val_loss: 1287.1816\n",
      "Epoch 626/1000\n",
      "41/41 [==============================] - 0s 190us/step - loss: 2299.6235 - val_loss: 2423.5654\n",
      "Epoch 627/1000\n",
      "41/41 [==============================] - 0s 102us/step - loss: 2083.7495 - val_loss: 1303.4222\n",
      "Epoch 628/1000\n",
      "41/41 [==============================] - 0s 161us/step - loss: 2235.4294 - val_loss: 2561.3567\n",
      "Epoch 629/1000\n",
      "41/41 [==============================] - 0s 100us/step - loss: 2063.7729 - val_loss: 1205.3824\n",
      "Epoch 630/1000\n",
      "41/41 [==============================] - 0s 138us/step - loss: 2382.3145 - val_loss: 2797.5930\n",
      "Epoch 631/1000\n",
      "41/41 [==============================] - 0s 176us/step - loss: 2213.4041 - val_loss: 1086.8257\n",
      "Epoch 632/1000\n",
      "41/41 [==============================] - 0s 136us/step - loss: 2347.4658 - val_loss: 2741.9243\n",
      "Epoch 633/1000\n",
      "41/41 [==============================] - 0s 106us/step - loss: 2113.5388 - val_loss: 922.3088\n",
      "Epoch 634/1000\n",
      "41/41 [==============================] - 0s 112us/step - loss: 2281.2576 - val_loss: 2732.8708\n",
      "Epoch 635/1000\n",
      "41/41 [==============================] - 0s 183us/step - loss: 2113.8269 - val_loss: 938.2938\n",
      "Epoch 636/1000\n",
      "41/41 [==============================] - 0s 129us/step - loss: 2311.1099 - val_loss: 2540.6301\n",
      "Epoch 637/1000\n",
      "41/41 [==============================] - 0s 114us/step - loss: 2013.5298 - val_loss: 1022.8330\n",
      "Epoch 638/1000\n",
      "41/41 [==============================] - 0s 116us/step - loss: 2183.0388 - val_loss: 2497.0615\n",
      "Epoch 639/1000\n",
      "41/41 [==============================] - 0s 120us/step - loss: 2008.2914 - val_loss: 1192.6317\n",
      "Epoch 640/1000\n",
      "41/41 [==============================] - 0s 161us/step - loss: 2139.0833 - val_loss: 2351.1130\n",
      "Epoch 641/1000\n",
      "41/41 [==============================] - 0s 98us/step - loss: 1981.3513 - val_loss: 1232.6687\n",
      "Epoch 642/1000\n",
      "41/41 [==============================] - 0s 132us/step - loss: 2047.8483 - val_loss: 2502.9048\n",
      "Epoch 643/1000\n",
      "41/41 [==============================] - 0s 114us/step - loss: 1997.7633 - val_loss: 1029.3007\n",
      "Epoch 644/1000\n",
      "41/41 [==============================] - 0s 97us/step - loss: 2173.1887 - val_loss: 2943.3381\n",
      "Epoch 645/1000\n",
      "41/41 [==============================] - 0s 200us/step - loss: 2241.1477 - val_loss: 1097.7598\n",
      "Epoch 646/1000\n",
      "41/41 [==============================] - 0s 96us/step - loss: 2441.3962 - val_loss: 2806.0339\n",
      "Epoch 647/1000\n",
      "41/41 [==============================] - 0s 156us/step - loss: 2220.9233 - val_loss: 1146.8894\n",
      "Epoch 648/1000\n",
      "41/41 [==============================] - 0s 141us/step - loss: 2357.7983 - val_loss: 2715.0662\n",
      "Epoch 649/1000\n",
      "41/41 [==============================] - 0s 109us/step - loss: 2080.5630 - val_loss: 935.4307\n",
      "Epoch 650/1000\n",
      "41/41 [==============================] - 0s 134us/step - loss: 2309.7200 - val_loss: 2890.2087\n",
      "Epoch 651/1000\n",
      "41/41 [==============================] - 0s 173us/step - loss: 2208.1826 - val_loss: 1085.9940\n",
      "Epoch 652/1000\n",
      "41/41 [==============================] - 0s 134us/step - loss: 2465.4678 - val_loss: 2658.0212\n",
      "Epoch 653/1000\n",
      "41/41 [==============================] - 0s 171us/step - loss: 2167.8643 - val_loss: 1072.1613\n",
      "Epoch 654/1000\n",
      "41/41 [==============================] - 0s 110us/step - loss: 2209.6245 - val_loss: 2487.7522\n",
      "Epoch 655/1000\n",
      "41/41 [==============================] - 0s 169us/step - loss: 2090.1487 - val_loss: 1279.4253\n",
      "Epoch 656/1000\n",
      "41/41 [==============================] - 0s 110us/step - loss: 2291.5647 - val_loss: 2368.2812\n",
      "Epoch 657/1000\n",
      "41/41 [==============================] - 0s 170us/step - loss: 2035.7338 - val_loss: 1285.2911\n",
      "Epoch 658/1000\n",
      "41/41 [==============================] - 0s 97us/step - loss: 2184.2686 - val_loss: 2380.4158\n",
      "Epoch 659/1000\n",
      "41/41 [==============================] - 0s 154us/step - loss: 2021.3243 - val_loss: 1232.9468\n",
      "Epoch 660/1000\n",
      "41/41 [==============================] - 0s 124us/step - loss: 2239.3076 - val_loss: 2595.2849\n",
      "Epoch 661/1000\n",
      "41/41 [==============================] - 0s 134us/step - loss: 2071.5764 - val_loss: 1021.7482\n",
      "Epoch 662/1000\n",
      "41/41 [==============================] - 0s 167us/step - loss: 2254.8459 - val_loss: 2627.2412\n",
      "Epoch 663/1000\n",
      "41/41 [==============================] - 0s 132us/step - loss: 2030.6454 - val_loss: 851.6697\n",
      "Epoch 664/1000\n",
      "41/41 [==============================] - 0s 133us/step - loss: 2224.3770 - val_loss: 2753.7341\n",
      "Epoch 665/1000\n",
      "41/41 [==============================] - 0s 88us/step - loss: 2091.4419 - val_loss: 919.6160\n",
      "Epoch 666/1000\n",
      "41/41 [==============================] - 0s 116us/step - loss: 2278.9111 - val_loss: 2631.6365\n",
      "Epoch 667/1000\n",
      "41/41 [==============================] - 0s 104us/step - loss: 2071.9495 - val_loss: 1089.4341\n",
      "Epoch 668/1000\n",
      "41/41 [==============================] - 0s 122us/step - loss: 2210.0894 - val_loss: 2539.6233\n",
      "Epoch 669/1000\n",
      "41/41 [==============================] - 0s 135us/step - loss: 2035.1022 - val_loss: 1092.5077\n",
      "Epoch 670/1000\n",
      "41/41 [==============================] - 0s 93us/step - loss: 2135.3713 - val_loss: 2639.1357\n",
      "Epoch 671/1000\n",
      "41/41 [==============================] - 0s 162us/step - loss: 2039.6729 - val_loss: 931.6848\n",
      "Epoch 672/1000\n",
      "41/41 [==============================] - 0s 154us/step - loss: 2136.6021 - val_loss: 2706.2285\n",
      "Epoch 673/1000\n",
      "41/41 [==============================] - 0s 171us/step - loss: 2063.8660 - val_loss: 1008.3696\n",
      "Epoch 674/1000\n",
      "41/41 [==============================] - 0s 113us/step - loss: 2266.7925 - val_loss: 2502.7258\n",
      "Epoch 675/1000\n",
      "41/41 [==============================] - 0s 125us/step - loss: 2025.5339 - val_loss: 1078.2535\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 676/1000\n",
      "41/41 [==============================] - 0s 108us/step - loss: 2197.1514 - val_loss: 2638.7009\n",
      "Epoch 677/1000\n",
      "41/41 [==============================] - 0s 84us/step - loss: 2154.0613 - val_loss: 1526.4821\n",
      "Epoch 678/1000\n",
      "41/41 [==============================] - 0s 214us/step - loss: 2566.9912 - val_loss: 2523.1687\n",
      "Epoch 679/1000\n",
      "41/41 [==============================] - 0s 81us/step - loss: 2073.6877 - val_loss: 1204.6519\n",
      "Epoch 680/1000\n",
      "41/41 [==============================] - 0s 115us/step - loss: 2267.0178 - val_loss: 2606.8491\n",
      "Epoch 681/1000\n",
      "41/41 [==============================] - 0s 161us/step - loss: 2039.3291 - val_loss: 907.1129\n",
      "Epoch 682/1000\n",
      "41/41 [==============================] - 0s 138us/step - loss: 2251.3398 - val_loss: 2787.8525\n",
      "Epoch 683/1000\n",
      "41/41 [==============================] - 0s 183us/step - loss: 2173.3076 - val_loss: 1021.8981\n",
      "Epoch 684/1000\n",
      "41/41 [==============================] - 0s 133us/step - loss: 2248.3801 - val_loss: 2363.0576\n",
      "Epoch 685/1000\n",
      "41/41 [==============================] - 0s 127us/step - loss: 1987.4630 - val_loss: 1076.1926\n",
      "Epoch 686/1000\n",
      "41/41 [==============================] - 0s 127us/step - loss: 2066.3694 - val_loss: 2440.1338\n",
      "Epoch 687/1000\n",
      "41/41 [==============================] - 0s 149us/step - loss: 2032.0648 - val_loss: 1153.4520\n",
      "Epoch 688/1000\n",
      "41/41 [==============================] - 0s 196us/step - loss: 2220.3862 - val_loss: 3037.5830\n",
      "Epoch 689/1000\n",
      "41/41 [==============================] - 0s 103us/step - loss: 2415.9827 - val_loss: 1423.0692\n",
      "Epoch 690/1000\n",
      "41/41 [==============================] - 0s 118us/step - loss: 2555.7773 - val_loss: 2477.7852\n",
      "Epoch 691/1000\n",
      "41/41 [==============================] - 0s 135us/step - loss: 1966.2225 - val_loss: 955.2292\n",
      "Epoch 692/1000\n",
      "41/41 [==============================] - 0s 112us/step - loss: 2124.1975 - val_loss: 2531.6912\n",
      "Epoch 693/1000\n",
      "41/41 [==============================] - 0s 115us/step - loss: 1982.3210 - val_loss: 875.6965\n",
      "Epoch 694/1000\n",
      "41/41 [==============================] - 0s 99us/step - loss: 2104.6990 - val_loss: 2515.4700\n",
      "Epoch 695/1000\n",
      "41/41 [==============================] - 0s 129us/step - loss: 1992.2329 - val_loss: 943.7495\n",
      "Epoch 696/1000\n",
      "41/41 [==============================] - 0s 223us/step - loss: 2152.9124 - val_loss: 2594.7903\n",
      "Epoch 697/1000\n",
      "41/41 [==============================] - 0s 188us/step - loss: 2057.9468 - val_loss: 1169.2977\n",
      "Epoch 698/1000\n",
      "41/41 [==============================] - 0s 128us/step - loss: 2330.7686 - val_loss: 2688.3718\n",
      "Epoch 699/1000\n",
      "41/41 [==============================] - 0s 129us/step - loss: 2153.4490 - val_loss: 1227.2328\n",
      "Epoch 700/1000\n",
      "41/41 [==============================] - 0s 117us/step - loss: 2348.8286 - val_loss: 2759.5491\n",
      "Epoch 701/1000\n",
      "41/41 [==============================] - 0s 94us/step - loss: 2153.2898 - val_loss: 1173.6544\n",
      "Epoch 702/1000\n",
      "41/41 [==============================] - 0s 97us/step - loss: 2473.5051 - val_loss: 2815.9924\n",
      "Epoch 703/1000\n",
      "41/41 [==============================] - 0s 134us/step - loss: 2124.2583 - val_loss: 838.4568\n",
      "Epoch 704/1000\n",
      "41/41 [==============================] - 0s 145us/step - loss: 2259.2878 - val_loss: 2668.0298\n",
      "Epoch 705/1000\n",
      "41/41 [==============================] - 0s 123us/step - loss: 2042.1244 - val_loss: 1053.2391\n",
      "Epoch 706/1000\n",
      "41/41 [==============================] - 0s 126us/step - loss: 2248.8765 - val_loss: 2525.1323\n",
      "Epoch 707/1000\n",
      "41/41 [==============================] - 0s 111us/step - loss: 2048.7979 - val_loss: 1164.7501\n",
      "Epoch 708/1000\n",
      "41/41 [==============================] - 0s 122us/step - loss: 2103.2002 - val_loss: 2347.0173\n",
      "Epoch 709/1000\n",
      "41/41 [==============================] - 0s 118us/step - loss: 1928.8848 - val_loss: 1130.6958\n",
      "Epoch 710/1000\n",
      "41/41 [==============================] - 0s 142us/step - loss: 2023.0787 - val_loss: 2584.2756\n",
      "Epoch 711/1000\n",
      "41/41 [==============================] - 0s 134us/step - loss: 2046.2201 - val_loss: 1224.9385\n",
      "Epoch 712/1000\n",
      "41/41 [==============================] - 0s 165us/step - loss: 2378.0940 - val_loss: 3267.9666\n",
      "Epoch 713/1000\n",
      "41/41 [==============================] - 0s 102us/step - loss: 2498.8352 - val_loss: 1460.8605\n",
      "Epoch 714/1000\n",
      "41/41 [==============================] - 0s 139us/step - loss: 2873.3516 - val_loss: 2895.1829\n",
      "Epoch 715/1000\n",
      "41/41 [==============================] - 0s 150us/step - loss: 2240.7180 - val_loss: 1091.2616\n",
      "Epoch 716/1000\n",
      "41/41 [==============================] - 0s 125us/step - loss: 2344.7402 - val_loss: 2622.6565\n",
      "Epoch 717/1000\n",
      "41/41 [==============================] - 0s 131us/step - loss: 2159.5198 - val_loss: 1205.6001\n",
      "Epoch 718/1000\n",
      "41/41 [==============================] - 0s 128us/step - loss: 2269.3364 - val_loss: 2449.8306\n",
      "Epoch 719/1000\n",
      "41/41 [==============================] - 0s 128us/step - loss: 2147.8069 - val_loss: 1257.9426\n",
      "Epoch 720/1000\n",
      "41/41 [==============================] - 0s 135us/step - loss: 2054.8503 - val_loss: 2281.5125\n",
      "Epoch 721/1000\n",
      "41/41 [==============================] - 0s 149us/step - loss: 2052.8735 - val_loss: 1287.2731\n",
      "Epoch 722/1000\n",
      "41/41 [==============================] - 0s 135us/step - loss: 2123.1445 - val_loss: 2418.4944\n",
      "Epoch 723/1000\n",
      "41/41 [==============================] - 0s 237us/step - loss: 2036.9301 - val_loss: 1237.8397\n",
      "Epoch 724/1000\n",
      "41/41 [==============================] - 0s 149us/step - loss: 2281.3313 - val_loss: 2749.1396\n",
      "Epoch 725/1000\n",
      "41/41 [==============================] - 0s 117us/step - loss: 2165.7371 - val_loss: 1180.4702\n",
      "Epoch 726/1000\n",
      "41/41 [==============================] - 0s 163us/step - loss: 2387.9971 - val_loss: 2768.6560\n",
      "Epoch 727/1000\n",
      "41/41 [==============================] - 0s 165us/step - loss: 2103.3357 - val_loss: 1080.9103\n",
      "Epoch 728/1000\n",
      "41/41 [==============================] - 0s 153us/step - loss: 2331.1104 - val_loss: 3207.4768\n",
      "Epoch 729/1000\n",
      "41/41 [==============================] - 0s 125us/step - loss: 2401.2271 - val_loss: 1132.7117\n",
      "Epoch 730/1000\n",
      "41/41 [==============================] - 0s 152us/step - loss: 2569.4458 - val_loss: 2652.6768\n",
      "Epoch 731/1000\n",
      "41/41 [==============================] - 0s 148us/step - loss: 2020.9546 - val_loss: 805.7842\n",
      "Epoch 732/1000\n",
      "41/41 [==============================] - 0s 158us/step - loss: 2113.2234 - val_loss: 2750.7725\n",
      "Epoch 733/1000\n",
      "41/41 [==============================] - 0s 129us/step - loss: 2098.1479 - val_loss: 1032.1265\n",
      "Epoch 734/1000\n",
      "41/41 [==============================] - 0s 165us/step - loss: 2269.7275 - val_loss: 2517.3687\n",
      "Epoch 735/1000\n",
      "41/41 [==============================] - 0s 102us/step - loss: 2069.1206 - val_loss: 1203.1156\n",
      "Epoch 736/1000\n",
      "41/41 [==============================] - 0s 119us/step - loss: 2072.3940 - val_loss: 2204.1943\n",
      "Epoch 737/1000\n",
      "41/41 [==============================] - 0s 140us/step - loss: 1921.8464 - val_loss: 1282.8989\n",
      "Epoch 738/1000\n",
      "41/41 [==============================] - 0s 154us/step - loss: 1982.5505 - val_loss: 2226.6650\n",
      "Epoch 739/1000\n",
      "41/41 [==============================] - 0s 123us/step - loss: 1953.8374 - val_loss: 1505.8828\n",
      "Epoch 740/1000\n",
      "41/41 [==============================] - 0s 125us/step - loss: 2221.9346 - val_loss: 2437.5930\n",
      "Epoch 741/1000\n",
      "41/41 [==============================] - 0s 128us/step - loss: 2210.5872 - val_loss: 1518.1464\n",
      "Epoch 742/1000\n",
      "41/41 [==============================] - 0s 139us/step - loss: 2209.9785 - val_loss: 2357.1418\n",
      "Epoch 743/1000\n",
      "41/41 [==============================] - 0s 126us/step - loss: 2014.5940 - val_loss: 1265.1329\n",
      "Epoch 744/1000\n",
      "41/41 [==============================] - 0s 146us/step - loss: 2210.0278 - val_loss: 2633.3608\n",
      "Epoch 745/1000\n",
      "41/41 [==============================] - 0s 159us/step - loss: 2091.1670 - val_loss: 954.7744\n",
      "Epoch 746/1000\n",
      "41/41 [==============================] - 0s 137us/step - loss: 2343.2549 - val_loss: 3039.4006\n",
      "Epoch 747/1000\n",
      "41/41 [==============================] - 0s 129us/step - loss: 2284.2869 - val_loss: 1228.0424\n",
      "Epoch 748/1000\n",
      "41/41 [==============================] - 0s 100us/step - loss: 2640.2053 - val_loss: 2747.9670\n",
      "Epoch 749/1000\n",
      "41/41 [==============================] - 0s 170us/step - loss: 2124.8918 - val_loss: 1016.8591\n",
      "Epoch 750/1000\n",
      "41/41 [==============================] - 0s 109us/step - loss: 2256.3640 - val_loss: 2595.9561\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 751/1000\n",
      "41/41 [==============================] - 0s 137us/step - loss: 1997.7883 - val_loss: 983.3552\n",
      "Epoch 752/1000\n",
      "41/41 [==============================] - 0s 139us/step - loss: 2154.2686 - val_loss: 2696.5261\n",
      "Epoch 753/1000\n",
      "41/41 [==============================] - 0s 179us/step - loss: 2050.4470 - val_loss: 1046.7734\n",
      "Epoch 754/1000\n",
      "41/41 [==============================] - 0s 126us/step - loss: 2177.9939 - val_loss: 2551.6963\n",
      "Epoch 755/1000\n",
      "41/41 [==============================] - 0s 112us/step - loss: 1979.9718 - val_loss: 1024.0266\n",
      "Epoch 756/1000\n",
      "41/41 [==============================] - 0s 117us/step - loss: 2133.3865 - val_loss: 2663.0974\n",
      "Epoch 757/1000\n",
      "41/41 [==============================] - 0s 125us/step - loss: 2043.3948 - val_loss: 1052.7462\n",
      "Epoch 758/1000\n",
      "41/41 [==============================] - 0s 141us/step - loss: 2244.7070 - val_loss: 2560.5933\n",
      "Epoch 759/1000\n",
      "41/41 [==============================] - 0s 232us/step - loss: 2062.8276 - val_loss: 1119.4050\n",
      "Epoch 760/1000\n",
      "41/41 [==============================] - 0s 183us/step - loss: 2236.8164 - val_loss: 2500.3669\n",
      "Epoch 761/1000\n",
      "41/41 [==============================] - 0s 114us/step - loss: 2118.8154 - val_loss: 1063.0109\n",
      "Epoch 762/1000\n",
      "41/41 [==============================] - 0s 164us/step - loss: 2165.0596 - val_loss: 2827.8186\n",
      "Epoch 763/1000\n",
      "41/41 [==============================] - 0s 224us/step - loss: 2264.8740 - val_loss: 1014.9459\n",
      "Epoch 764/1000\n",
      "41/41 [==============================] - 0s 123us/step - loss: 2338.4668 - val_loss: 2797.8870\n",
      "Epoch 765/1000\n",
      "41/41 [==============================] - 0s 159us/step - loss: 2164.0457 - val_loss: 1156.2285\n",
      "Epoch 766/1000\n",
      "41/41 [==============================] - 0s 119us/step - loss: 2434.7817 - val_loss: 2673.7480\n",
      "Epoch 767/1000\n",
      "41/41 [==============================] - 0s 115us/step - loss: 2117.6079 - val_loss: 1118.6160\n",
      "Epoch 768/1000\n",
      "41/41 [==============================] - 0s 173us/step - loss: 2242.5439 - val_loss: 2497.0120\n",
      "Epoch 769/1000\n",
      "41/41 [==============================] - 0s 154us/step - loss: 1954.1704 - val_loss: 1012.2141\n",
      "Epoch 770/1000\n",
      "41/41 [==============================] - 0s 96us/step - loss: 2140.5378 - val_loss: 2616.7178\n",
      "Epoch 771/1000\n",
      "41/41 [==============================] - 0s 112us/step - loss: 2020.7593 - val_loss: 1039.1187\n",
      "Epoch 772/1000\n",
      "41/41 [==============================] - 0s 126us/step - loss: 2206.6975 - val_loss: 2598.0908\n",
      "Epoch 773/1000\n",
      "41/41 [==============================] - 0s 135us/step - loss: 2030.8954 - val_loss: 1045.9128\n",
      "Epoch 774/1000\n",
      "41/41 [==============================] - 0s 140us/step - loss: 2164.2422 - val_loss: 2684.5999\n",
      "Epoch 775/1000\n",
      "41/41 [==============================] - 0s 143us/step - loss: 2135.5227 - val_loss: 1027.7963\n",
      "Epoch 776/1000\n",
      "41/41 [==============================] - 0s 189us/step - loss: 2182.5640 - val_loss: 2523.9880\n",
      "Epoch 777/1000\n",
      "41/41 [==============================] - 0s 105us/step - loss: 2019.0693 - val_loss: 967.5383\n",
      "Epoch 778/1000\n",
      "41/41 [==============================] - 0s 119us/step - loss: 2165.9436 - val_loss: 2815.9255\n",
      "Epoch 779/1000\n",
      "41/41 [==============================] - 0s 105us/step - loss: 2220.4358 - val_loss: 1398.9249\n",
      "Epoch 780/1000\n",
      "41/41 [==============================] - 0s 106us/step - loss: 2492.8140 - val_loss: 2446.7583\n",
      "Epoch 781/1000\n",
      "41/41 [==============================] - 0s 119us/step - loss: 1980.5587 - val_loss: 1025.6200\n",
      "Epoch 782/1000\n",
      "41/41 [==============================] - 0s 148us/step - loss: 2163.7903 - val_loss: 2605.7312\n",
      "Epoch 783/1000\n",
      "41/41 [==============================] - 0s 97us/step - loss: 2030.4612 - val_loss: 958.8113\n",
      "Epoch 784/1000\n",
      "41/41 [==============================] - 0s 94us/step - loss: 2149.8926 - val_loss: 2521.0608\n",
      "Epoch 785/1000\n",
      "41/41 [==============================] - 0s 252us/step - loss: 1994.0071 - val_loss: 988.8365\n",
      "Epoch 786/1000\n",
      "41/41 [==============================] - 0s 106us/step - loss: 2082.1614 - val_loss: 2530.8926\n",
      "Epoch 787/1000\n",
      "41/41 [==============================] - 0s 167us/step - loss: 2012.7853 - val_loss: 1042.8201\n",
      "Epoch 788/1000\n",
      "41/41 [==============================] - 0s 123us/step - loss: 2103.2209 - val_loss: 2503.1990\n",
      "Epoch 789/1000\n",
      "41/41 [==============================] - 0s 127us/step - loss: 2005.4246 - val_loss: 1084.8453\n",
      "Epoch 790/1000\n",
      "41/41 [==============================] - 0s 124us/step - loss: 2142.5850 - val_loss: 2679.2517\n",
      "Epoch 791/1000\n",
      "41/41 [==============================] - 0s 176us/step - loss: 2111.8181 - val_loss: 1254.6515\n",
      "Epoch 792/1000\n",
      "41/41 [==============================] - 0s 153us/step - loss: 2341.8804 - val_loss: 2633.5515\n",
      "Epoch 793/1000\n",
      "41/41 [==============================] - 0s 105us/step - loss: 2126.2856 - val_loss: 1260.1365\n",
      "Epoch 794/1000\n",
      "41/41 [==============================] - 0s 121us/step - loss: 2313.1343 - val_loss: 2798.4492\n",
      "Epoch 795/1000\n",
      "41/41 [==============================] - 0s 109us/step - loss: 2110.6060 - val_loss: 1036.8230\n",
      "Epoch 796/1000\n",
      "41/41 [==============================] - 0s 146us/step - loss: 2414.3525 - val_loss: 2776.3748\n",
      "Epoch 797/1000\n",
      "41/41 [==============================] - 0s 254us/step - loss: 2092.9104 - val_loss: 831.5048\n",
      "Epoch 798/1000\n",
      "41/41 [==============================] - 0s 113us/step - loss: 2262.0010 - val_loss: 2638.0911\n",
      "Epoch 799/1000\n",
      "41/41 [==============================] - 0s 124us/step - loss: 2041.4053 - val_loss: 1145.7871\n",
      "Epoch 800/1000\n",
      "41/41 [==============================] - 0s 105us/step - loss: 2204.4192 - val_loss: 2400.0186\n",
      "Epoch 801/1000\n",
      "41/41 [==============================] - 0s 123us/step - loss: 2089.0847 - val_loss: 1516.0062\n",
      "Epoch 802/1000\n",
      "41/41 [==============================] - 0s 127us/step - loss: 2129.5403 - val_loss: 1973.4087\n",
      "Epoch 803/1000\n",
      "41/41 [==============================] - 0s 123us/step - loss: 1862.2961 - val_loss: 1462.9664\n",
      "Epoch 804/1000\n",
      "41/41 [==============================] - 0s 125us/step - loss: 1915.0853 - val_loss: 1964.8516\n",
      "Epoch 805/1000\n",
      "41/41 [==============================] - 0s 117us/step - loss: 1880.7418 - val_loss: 1564.6118\n",
      "Epoch 806/1000\n",
      "41/41 [==============================] - 0s 103us/step - loss: 1967.0640 - val_loss: 2127.0842\n",
      "Epoch 807/1000\n",
      "41/41 [==============================] - 0s 124us/step - loss: 1893.4464 - val_loss: 1298.1608\n",
      "Epoch 808/1000\n",
      "41/41 [==============================] - 0s 164us/step - loss: 2009.5074 - val_loss: 2963.5586\n",
      "Epoch 809/1000\n",
      "41/41 [==============================] - 0s 117us/step - loss: 2197.4600 - val_loss: 1246.6270\n",
      "Epoch 810/1000\n",
      "41/41 [==============================] - 0s 135us/step - loss: 2732.4316 - val_loss: 3250.3389\n",
      "Epoch 811/1000\n",
      "41/41 [==============================] - 0s 91us/step - loss: 2383.2129 - val_loss: 1029.0403\n",
      "Epoch 812/1000\n",
      "41/41 [==============================] - 0s 115us/step - loss: 2537.0149 - val_loss: 2746.7542\n",
      "Epoch 813/1000\n",
      "41/41 [==============================] - 0s 110us/step - loss: 2079.3770 - val_loss: 787.8482\n",
      "Epoch 814/1000\n",
      "41/41 [==============================] - 0s 129us/step - loss: 2262.5244 - val_loss: 2745.3186\n",
      "Epoch 815/1000\n",
      "41/41 [==============================] - 0s 113us/step - loss: 2067.3928 - val_loss: 843.6500\n",
      "Epoch 816/1000\n",
      "41/41 [==============================] - 0s 110us/step - loss: 2192.6377 - val_loss: 2426.7720\n",
      "Epoch 817/1000\n",
      "41/41 [==============================] - 0s 128us/step - loss: 1952.9966 - val_loss: 965.8748\n",
      "Epoch 818/1000\n",
      "41/41 [==============================] - 0s 102us/step - loss: 2020.6824 - val_loss: 2281.1907\n",
      "Epoch 819/1000\n",
      "41/41 [==============================] - 0s 110us/step - loss: 1910.6118 - val_loss: 1134.9036\n",
      "Epoch 820/1000\n",
      "41/41 [==============================] - 0s 133us/step - loss: 2006.0526 - val_loss: 2386.4326\n",
      "Epoch 821/1000\n",
      "41/41 [==============================] - 0s 131us/step - loss: 2041.2599 - val_loss: 1470.0302\n",
      "Epoch 822/1000\n",
      "41/41 [==============================] - 0s 153us/step - loss: 2294.8389 - val_loss: 2554.9683\n",
      "Epoch 823/1000\n",
      "41/41 [==============================] - 0s 153us/step - loss: 2082.1921 - val_loss: 1252.2101\n",
      "Epoch 824/1000\n",
      "41/41 [==============================] - 0s 107us/step - loss: 2258.2268 - val_loss: 2713.3171\n",
      "Epoch 825/1000\n",
      "41/41 [==============================] - 0s 104us/step - loss: 2086.4124 - val_loss: 992.1548\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 826/1000\n",
      "41/41 [==============================] - 0s 142us/step - loss: 2291.7998 - val_loss: 2842.6531\n",
      "Epoch 827/1000\n",
      "41/41 [==============================] - 0s 113us/step - loss: 2110.4343 - val_loss: 799.9775\n",
      "Epoch 828/1000\n",
      "41/41 [==============================] - 0s 127us/step - loss: 2246.8142 - val_loss: 2735.4919\n",
      "Epoch 829/1000\n",
      "41/41 [==============================] - 0s 139us/step - loss: 2049.6128 - val_loss: 839.0489\n",
      "Epoch 830/1000\n",
      "41/41 [==============================] - 0s 131us/step - loss: 2222.5439 - val_loss: 2828.2803\n",
      "Epoch 831/1000\n",
      "41/41 [==============================] - 0s 113us/step - loss: 2161.3784 - val_loss: 1196.9739\n",
      "Epoch 832/1000\n",
      "41/41 [==============================] - 0s 129us/step - loss: 2444.5525 - val_loss: 2686.6047\n",
      "Epoch 833/1000\n",
      "41/41 [==============================] - 0s 94us/step - loss: 2138.8540 - val_loss: 1214.3094\n",
      "Epoch 834/1000\n",
      "41/41 [==============================] - 0s 144us/step - loss: 2291.9414 - val_loss: 2529.9812\n",
      "Epoch 835/1000\n",
      "41/41 [==============================] - 0s 141us/step - loss: 1999.8149 - val_loss: 1204.4498\n",
      "Epoch 836/1000\n",
      "41/41 [==============================] - 0s 103us/step - loss: 2130.5393 - val_loss: 2391.8088\n",
      "Epoch 837/1000\n",
      "41/41 [==============================] - 0s 153us/step - loss: 1980.5587 - val_loss: 1309.9510\n",
      "Epoch 838/1000\n",
      "41/41 [==============================] - 0s 188us/step - loss: 2081.5593 - val_loss: 2228.9822\n",
      "Epoch 839/1000\n",
      "41/41 [==============================] - 0s 192us/step - loss: 1907.6182 - val_loss: 1229.9581\n",
      "Epoch 840/1000\n",
      "41/41 [==============================] - 0s 138us/step - loss: 1965.3990 - val_loss: 2488.2419\n",
      "Epoch 841/1000\n",
      "41/41 [==============================] - 0s 151us/step - loss: 1969.7001 - val_loss: 1048.5883\n",
      "Epoch 842/1000\n",
      "41/41 [==============================] - 0s 158us/step - loss: 2212.8057 - val_loss: 2917.4709\n",
      "Epoch 843/1000\n",
      "41/41 [==============================] - 0s 164us/step - loss: 2216.3250 - val_loss: 1001.5488\n",
      "Epoch 844/1000\n",
      "41/41 [==============================] - 0s 122us/step - loss: 2317.1423 - val_loss: 2751.8872\n",
      "Epoch 845/1000\n",
      "41/41 [==============================] - 0s 133us/step - loss: 2086.5134 - val_loss: 870.5381\n",
      "Epoch 846/1000\n",
      "41/41 [==============================] - 0s 150us/step - loss: 2221.4858 - val_loss: 2796.3225\n",
      "Epoch 847/1000\n",
      "41/41 [==============================] - 0s 135us/step - loss: 2094.6262 - val_loss: 1192.4902\n",
      "Epoch 848/1000\n",
      "41/41 [==============================] - 0s 139us/step - loss: 2415.0730 - val_loss: 3135.2727\n",
      "Epoch 849/1000\n",
      "41/41 [==============================] - 0s 196us/step - loss: 2555.3413 - val_loss: 1788.1964\n",
      "Epoch 850/1000\n",
      "41/41 [==============================] - 0s 129us/step - loss: 2668.2146 - val_loss: 3487.2458\n",
      "Epoch 851/1000\n",
      "41/41 [==============================] - 0s 169us/step - loss: 2908.5073 - val_loss: 2436.0251\n",
      "Epoch 852/1000\n",
      "41/41 [==============================] - 0s 183us/step - loss: 3566.4805 - val_loss: 3745.5491\n",
      "Epoch 853/1000\n",
      "41/41 [==============================] - 0s 162us/step - loss: 2867.6707 - val_loss: 1475.3384\n",
      "Epoch 854/1000\n",
      "41/41 [==============================] - 0s 129us/step - loss: 3114.1023 - val_loss: 4317.5229\n",
      "Epoch 855/1000\n",
      "41/41 [==============================] - 0s 224us/step - loss: 3379.1494 - val_loss: 2166.2415\n",
      "Epoch 856/1000\n",
      "41/41 [==============================] - 0s 117us/step - loss: 3482.0110 - val_loss: 3854.0796\n",
      "Epoch 857/1000\n",
      "41/41 [==============================] - 0s 123us/step - loss: 3143.9849 - val_loss: 2005.5323\n",
      "Epoch 858/1000\n",
      "41/41 [==============================] - 0s 151us/step - loss: 3186.8823 - val_loss: 2394.1140\n",
      "Epoch 859/1000\n",
      "41/41 [==============================] - 0s 165us/step - loss: 2019.2303 - val_loss: 1459.1328\n",
      "Epoch 860/1000\n",
      "41/41 [==============================] - 0s 160us/step - loss: 2221.4526 - val_loss: 2433.4614\n",
      "Epoch 861/1000\n",
      "41/41 [==============================] - 0s 169us/step - loss: 2145.3208 - val_loss: 1691.1093\n",
      "Epoch 862/1000\n",
      "41/41 [==============================] - 0s 152us/step - loss: 2311.1785 - val_loss: 2515.7561\n",
      "Epoch 863/1000\n",
      "41/41 [==============================] - 0s 144us/step - loss: 2270.6951 - val_loss: 1728.7504\n",
      "Epoch 864/1000\n",
      "41/41 [==============================] - 0s 129us/step - loss: 2414.8564 - val_loss: 2701.2427\n",
      "Epoch 865/1000\n",
      "41/41 [==============================] - 0s 117us/step - loss: 2382.1165 - val_loss: 1758.8610\n",
      "Epoch 866/1000\n",
      "41/41 [==============================] - 0s 186us/step - loss: 2608.9934 - val_loss: 2796.7629\n",
      "Epoch 867/1000\n",
      "41/41 [==============================] - 0s 142us/step - loss: 2279.1985 - val_loss: 1504.6727\n",
      "Epoch 868/1000\n",
      "41/41 [==============================] - 0s 152us/step - loss: 2603.0439 - val_loss: 2656.5747\n",
      "Epoch 869/1000\n",
      "41/41 [==============================] - 0s 185us/step - loss: 2050.9436 - val_loss: 1042.4077\n",
      "Epoch 870/1000\n",
      "41/41 [==============================] - 0s 156us/step - loss: 2258.6423 - val_loss: 2886.4077\n",
      "Epoch 871/1000\n",
      "41/41 [==============================] - 0s 155us/step - loss: 2143.6201 - val_loss: 956.5497\n",
      "Epoch 872/1000\n",
      "41/41 [==============================] - 0s 109us/step - loss: 2383.5996 - val_loss: 2846.3374\n",
      "Epoch 873/1000\n",
      "41/41 [==============================] - 0s 118us/step - loss: 2117.3933 - val_loss: 959.6754\n",
      "Epoch 874/1000\n",
      "41/41 [==============================] - 0s 145us/step - loss: 2319.3997 - val_loss: 2626.8818\n",
      "Epoch 875/1000\n",
      "41/41 [==============================] - 0s 164us/step - loss: 2017.3746 - val_loss: 928.4799\n",
      "Epoch 876/1000\n",
      "41/41 [==============================] - 0s 121us/step - loss: 2119.4089 - val_loss: 2621.3096\n",
      "Epoch 877/1000\n",
      "41/41 [==============================] - 0s 151us/step - loss: 2004.1814 - val_loss: 899.9192\n",
      "Epoch 878/1000\n",
      "41/41 [==============================] - 0s 112us/step - loss: 2116.9451 - val_loss: 2689.0159\n",
      "Epoch 879/1000\n",
      "41/41 [==============================] - 0s 129us/step - loss: 2070.3328 - val_loss: 1014.8205\n",
      "Epoch 880/1000\n",
      "41/41 [==============================] - 0s 119us/step - loss: 2210.8154 - val_loss: 2554.7439\n",
      "Epoch 881/1000\n",
      "41/41 [==============================] - 0s 101us/step - loss: 2031.4508 - val_loss: 1146.1899\n",
      "Epoch 882/1000\n",
      "41/41 [==============================] - 0s 109us/step - loss: 2164.2419 - val_loss: 2354.9795\n",
      "Epoch 883/1000\n",
      "41/41 [==============================] - 0s 99us/step - loss: 1957.3068 - val_loss: 1194.8403\n",
      "Epoch 884/1000\n",
      "41/41 [==============================] - 0s 120us/step - loss: 2053.6516 - val_loss: 2372.1101\n",
      "Epoch 885/1000\n",
      "41/41 [==============================] - 0s 131us/step - loss: 2002.4124 - val_loss: 1305.2700\n",
      "Epoch 886/1000\n",
      "41/41 [==============================] - 0s 164us/step - loss: 2188.4321 - val_loss: 2407.1848\n",
      "Epoch 887/1000\n",
      "41/41 [==============================] - 0s 245us/step - loss: 2008.5961 - val_loss: 1177.4009\n",
      "Epoch 888/1000\n",
      "41/41 [==============================] - 0s 117us/step - loss: 2097.8638 - val_loss: 2575.7932\n",
      "Epoch 889/1000\n",
      "41/41 [==============================] - 0s 97us/step - loss: 2023.3213 - val_loss: 1145.8278\n",
      "Epoch 890/1000\n",
      "41/41 [==============================] - 0s 122us/step - loss: 2294.2334 - val_loss: 2750.0430\n",
      "Epoch 891/1000\n",
      "41/41 [==============================] - 0s 119us/step - loss: 2126.5496 - val_loss: 1146.5094\n",
      "Epoch 892/1000\n",
      "41/41 [==============================] - 0s 155us/step - loss: 2338.7969 - val_loss: 2657.3430\n",
      "Epoch 893/1000\n",
      "41/41 [==============================] - 0s 118us/step - loss: 1993.7700 - val_loss: 908.9396\n",
      "Epoch 894/1000\n",
      "41/41 [==============================] - 0s 102us/step - loss: 2208.1597 - val_loss: 2718.5823\n",
      "Epoch 895/1000\n",
      "41/41 [==============================] - 0s 100us/step - loss: 2043.5272 - val_loss: 889.6157\n",
      "Epoch 896/1000\n",
      "41/41 [==============================] - 0s 99us/step - loss: 2149.0605 - val_loss: 2536.7952\n",
      "Epoch 897/1000\n",
      "41/41 [==============================] - 0s 184us/step - loss: 1966.0028 - val_loss: 887.2096\n",
      "Epoch 898/1000\n",
      "41/41 [==============================] - 0s 115us/step - loss: 2044.3605 - val_loss: 2611.1091\n",
      "Epoch 899/1000\n",
      "41/41 [==============================] - 0s 116us/step - loss: 2020.0706 - val_loss: 1030.7997\n",
      "Epoch 900/1000\n",
      "41/41 [==============================] - 0s 159us/step - loss: 2149.8291 - val_loss: 2511.8430\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 901/1000\n",
      "41/41 [==============================] - 0s 142us/step - loss: 2001.2820 - val_loss: 1018.1865\n",
      "Epoch 902/1000\n",
      "41/41 [==============================] - 0s 161us/step - loss: 2081.8210 - val_loss: 2684.5171\n",
      "Epoch 903/1000\n",
      "41/41 [==============================] - 0s 140us/step - loss: 2055.7292 - val_loss: 1112.7365\n",
      "Epoch 904/1000\n",
      "41/41 [==============================] - 0s 148us/step - loss: 2302.7522 - val_loss: 2645.1179\n",
      "Epoch 905/1000\n",
      "41/41 [==============================] - 0s 117us/step - loss: 2158.6199 - val_loss: 1171.2948\n",
      "Epoch 906/1000\n",
      "41/41 [==============================] - 0s 99us/step - loss: 2154.9604 - val_loss: 2496.3113\n",
      "Epoch 907/1000\n",
      "41/41 [==============================] - 0s 126us/step - loss: 2023.4785 - val_loss: 1203.8177\n",
      "Epoch 908/1000\n",
      "41/41 [==============================] - 0s 152us/step - loss: 2333.1731 - val_loss: 2776.1301\n",
      "Epoch 909/1000\n",
      "41/41 [==============================] - 0s 106us/step - loss: 2223.0742 - val_loss: 1249.2512\n",
      "Epoch 910/1000\n",
      "41/41 [==============================] - 0s 132us/step - loss: 2337.6890 - val_loss: 2491.3938\n",
      "Epoch 911/1000\n",
      "41/41 [==============================] - 0s 93us/step - loss: 1932.3033 - val_loss: 917.4697\n",
      "Epoch 912/1000\n",
      "41/41 [==============================] - 0s 119us/step - loss: 2102.3552 - val_loss: 2701.5210\n",
      "Epoch 913/1000\n",
      "41/41 [==============================] - 0s 111us/step - loss: 2005.2603 - val_loss: 873.2947\n",
      "Epoch 914/1000\n",
      "41/41 [==============================] - 0s 120us/step - loss: 2176.4448 - val_loss: 2680.5227\n",
      "Epoch 915/1000\n",
      "41/41 [==============================] - 0s 111us/step - loss: 2041.9131 - val_loss: 958.9533\n",
      "Epoch 916/1000\n",
      "41/41 [==============================] - 0s 114us/step - loss: 2122.5386 - val_loss: 2486.2593\n",
      "Epoch 917/1000\n",
      "41/41 [==============================] - 0s 109us/step - loss: 1980.0734 - val_loss: 1124.8661\n",
      "Epoch 918/1000\n",
      "41/41 [==============================] - 0s 90us/step - loss: 2078.3901 - val_loss: 2613.9924\n",
      "Epoch 919/1000\n",
      "41/41 [==============================] - 0s 119us/step - loss: 2090.8110 - val_loss: 1390.4868\n",
      "Epoch 920/1000\n",
      "41/41 [==============================] - 0s 98us/step - loss: 2282.4458 - val_loss: 2666.8071\n",
      "Epoch 921/1000\n",
      "41/41 [==============================] - 0s 97us/step - loss: 2197.8157 - val_loss: 1321.3983\n",
      "Epoch 922/1000\n",
      "41/41 [==============================] - 0s 124us/step - loss: 2263.9209 - val_loss: 2750.3640\n",
      "Epoch 923/1000\n",
      "41/41 [==============================] - 0s 111us/step - loss: 2054.3237 - val_loss: 990.5821\n",
      "Epoch 924/1000\n",
      "41/41 [==============================] - 0s 113us/step - loss: 2297.9546 - val_loss: 2858.9651\n",
      "Epoch 925/1000\n",
      "41/41 [==============================] - 0s 112us/step - loss: 2121.3401 - val_loss: 1024.5316\n",
      "Epoch 926/1000\n",
      "41/41 [==============================] - 0s 100us/step - loss: 2317.0547 - val_loss: 2632.3955\n",
      "Epoch 927/1000\n",
      "41/41 [==============================] - 0s 94us/step - loss: 2005.7996 - val_loss: 956.5375\n",
      "Epoch 928/1000\n",
      "41/41 [==============================] - 0s 157us/step - loss: 2132.6230 - val_loss: 2546.8225\n",
      "Epoch 929/1000\n",
      "41/41 [==============================] - 0s 123us/step - loss: 1980.2932 - val_loss: 1039.5613\n",
      "Epoch 930/1000\n",
      "41/41 [==============================] - 0s 91us/step - loss: 2159.8274 - val_loss: 2403.6689\n",
      "Epoch 931/1000\n",
      "41/41 [==============================] - 0s 136us/step - loss: 1988.1603 - val_loss: 1070.1410\n",
      "Epoch 932/1000\n",
      "41/41 [==============================] - 0s 178us/step - loss: 2076.0325 - val_loss: 2466.7849\n",
      "Epoch 933/1000\n",
      "41/41 [==============================] - 0s 116us/step - loss: 2035.6930 - val_loss: 1023.1947\n",
      "Epoch 934/1000\n",
      "41/41 [==============================] - 0s 121us/step - loss: 2036.1764 - val_loss: 2374.3987\n",
      "Epoch 935/1000\n",
      "41/41 [==============================] - 0s 125us/step - loss: 2003.7584 - val_loss: 1130.4972\n",
      "Epoch 936/1000\n",
      "41/41 [==============================] - 0s 112us/step - loss: 2036.2120 - val_loss: 2453.3477\n",
      "Epoch 937/1000\n",
      "41/41 [==============================] - 0s 120us/step - loss: 2034.7351 - val_loss: 1102.3595\n",
      "Epoch 938/1000\n",
      "41/41 [==============================] - 0s 116us/step - loss: 2328.9617 - val_loss: 3107.5234\n",
      "Epoch 939/1000\n",
      "41/41 [==============================] - 0s 122us/step - loss: 2359.7383 - val_loss: 1267.8273\n",
      "Epoch 940/1000\n",
      "41/41 [==============================] - 0s 125us/step - loss: 2574.4556 - val_loss: 2723.8191\n",
      "Epoch 941/1000\n",
      "41/41 [==============================] - 0s 138us/step - loss: 2061.1179 - val_loss: 1005.7873\n",
      "Epoch 942/1000\n",
      "41/41 [==============================] - 0s 123us/step - loss: 2336.4155 - val_loss: 2781.2415\n",
      "Epoch 943/1000\n",
      "41/41 [==============================] - 0s 117us/step - loss: 2098.2693 - val_loss: 952.6346\n",
      "Epoch 944/1000\n",
      "41/41 [==============================] - 0s 133us/step - loss: 2148.7603 - val_loss: 2464.8894\n",
      "Epoch 945/1000\n",
      "41/41 [==============================] - 0s 116us/step - loss: 1926.3094 - val_loss: 970.1270\n",
      "Epoch 946/1000\n",
      "41/41 [==============================] - 0s 143us/step - loss: 2001.4510 - val_loss: 2469.8135\n",
      "Epoch 947/1000\n",
      "41/41 [==============================] - 0s 115us/step - loss: 1941.9165 - val_loss: 1088.4110\n",
      "Epoch 948/1000\n",
      "41/41 [==============================] - 0s 105us/step - loss: 2084.7019 - val_loss: 2553.9204\n",
      "Epoch 949/1000\n",
      "41/41 [==============================] - 0s 124us/step - loss: 2015.8342 - val_loss: 1174.0435\n",
      "Epoch 950/1000\n",
      "41/41 [==============================] - 0s 135us/step - loss: 2176.8677 - val_loss: 2781.1729\n",
      "Epoch 951/1000\n",
      "41/41 [==============================] - 0s 292us/step - loss: 2150.6558 - val_loss: 1297.6007\n",
      "Epoch 952/1000\n",
      "41/41 [==============================] - 0s 107us/step - loss: 2506.8203 - val_loss: 3100.1990\n",
      "Epoch 953/1000\n",
      "41/41 [==============================] - 0s 160us/step - loss: 2338.6230 - val_loss: 973.3832\n",
      "Epoch 954/1000\n",
      "41/41 [==============================] - 0s 94us/step - loss: 2383.0872 - val_loss: 2751.8899\n",
      "Epoch 955/1000\n",
      "41/41 [==============================] - 0s 110us/step - loss: 2056.6057 - val_loss: 1115.7122\n",
      "Epoch 956/1000\n",
      "41/41 [==============================] - 0s 137us/step - loss: 2368.1433 - val_loss: 2545.1580\n",
      "Epoch 957/1000\n",
      "41/41 [==============================] - 0s 122us/step - loss: 2042.3064 - val_loss: 1139.4191\n",
      "Epoch 958/1000\n",
      "41/41 [==============================] - 0s 131us/step - loss: 2099.2205 - val_loss: 2345.3291\n",
      "Epoch 959/1000\n",
      "41/41 [==============================] - 0s 128us/step - loss: 1946.0404 - val_loss: 1142.4952\n",
      "Epoch 960/1000\n",
      "41/41 [==============================] - 0s 133us/step - loss: 1968.9996 - val_loss: 2364.7913\n",
      "Epoch 961/1000\n",
      "41/41 [==============================] - 0s 101us/step - loss: 1925.7462 - val_loss: 1150.4578\n",
      "Epoch 962/1000\n",
      "41/41 [==============================] - 0s 111us/step - loss: 2035.0071 - val_loss: 2541.0486\n",
      "Epoch 963/1000\n",
      "41/41 [==============================] - 0s 138us/step - loss: 2031.9347 - val_loss: 1122.3610\n",
      "Epoch 964/1000\n",
      "41/41 [==============================] - 0s 144us/step - loss: 2067.4612 - val_loss: 2414.8250\n",
      "Epoch 965/1000\n",
      "41/41 [==============================] - 0s 143us/step - loss: 1927.6895 - val_loss: 1002.5831\n",
      "Epoch 966/1000\n",
      "41/41 [==============================] - 0s 115us/step - loss: 1971.1895 - val_loss: 2560.2327\n",
      "Epoch 967/1000\n",
      "41/41 [==============================] - 0s 104us/step - loss: 2054.6309 - val_loss: 1066.9885\n",
      "Epoch 968/1000\n",
      "41/41 [==============================] - 0s 128us/step - loss: 2126.1177 - val_loss: 2322.5713\n",
      "Epoch 969/1000\n",
      "41/41 [==============================] - 0s 115us/step - loss: 1962.7599 - val_loss: 975.4739\n",
      "Epoch 970/1000\n",
      "41/41 [==============================] - 0s 174us/step - loss: 2197.2483 - val_loss: 3491.8843\n",
      "Epoch 971/1000\n",
      "41/41 [==============================] - 0s 99us/step - loss: 2684.8467 - val_loss: 1730.4512\n",
      "Epoch 972/1000\n",
      "41/41 [==============================] - 0s 138us/step - loss: 2981.5100 - val_loss: 2723.3000\n",
      "Epoch 973/1000\n",
      "41/41 [==============================] - 0s 159us/step - loss: 2083.8513 - val_loss: 1022.1756\n",
      "Epoch 974/1000\n",
      "41/41 [==============================] - 0s 113us/step - loss: 2218.4287 - val_loss: 2590.4482\n",
      "Epoch 975/1000\n",
      "41/41 [==============================] - 0s 128us/step - loss: 1973.7836 - val_loss: 945.2004\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 976/1000\n",
      "41/41 [==============================] - 0s 122us/step - loss: 2093.2571 - val_loss: 2516.3525\n",
      "Epoch 977/1000\n",
      "41/41 [==============================] - 0s 127us/step - loss: 1930.3279 - val_loss: 972.5256\n",
      "Epoch 978/1000\n",
      "41/41 [==============================] - 0s 147us/step - loss: 2052.2891 - val_loss: 2527.4670\n",
      "Epoch 979/1000\n",
      "41/41 [==============================] - 0s 100us/step - loss: 1963.5748 - val_loss: 1073.2761\n",
      "Epoch 980/1000\n",
      "41/41 [==============================] - 0s 121us/step - loss: 2046.6635 - val_loss: 2549.4846\n",
      "Epoch 981/1000\n",
      "41/41 [==============================] - 0s 153us/step - loss: 2044.5989 - val_loss: 1374.4840\n",
      "Epoch 982/1000\n",
      "41/41 [==============================] - 0s 142us/step - loss: 2177.6516 - val_loss: 2298.3411\n",
      "Epoch 983/1000\n",
      "41/41 [==============================] - 0s 171us/step - loss: 1964.7107 - val_loss: 1393.0522\n",
      "Epoch 984/1000\n",
      "41/41 [==============================] - 0s 114us/step - loss: 2063.9709 - val_loss: 2233.7478\n",
      "Epoch 985/1000\n",
      "41/41 [==============================] - 0s 158us/step - loss: 1960.4885 - val_loss: 1329.7931\n",
      "Epoch 986/1000\n",
      "41/41 [==============================] - 0s 93us/step - loss: 1993.6686 - val_loss: 2215.8135\n",
      "Epoch 987/1000\n",
      "41/41 [==============================] - 0s 129us/step - loss: 1906.9908 - val_loss: 1151.3601\n",
      "Epoch 988/1000\n",
      "41/41 [==============================] - 0s 185us/step - loss: 1991.9238 - val_loss: 2655.3130\n",
      "Epoch 989/1000\n",
      "41/41 [==============================] - 0s 118us/step - loss: 2069.8347 - val_loss: 1048.6914\n",
      "Epoch 990/1000\n",
      "41/41 [==============================] - 0s 95us/step - loss: 2404.2651 - val_loss: 3179.3438\n",
      "Epoch 991/1000\n",
      "41/41 [==============================] - 0s 165us/step - loss: 2384.8408 - val_loss: 1219.5870\n",
      "Epoch 992/1000\n",
      "41/41 [==============================] - 0s 141us/step - loss: 2565.2429 - val_loss: 3147.5969\n",
      "Epoch 993/1000\n",
      "41/41 [==============================] - 0s 127us/step - loss: 2339.4280 - val_loss: 1069.1522\n",
      "Epoch 994/1000\n",
      "41/41 [==============================] - 0s 115us/step - loss: 2479.4590 - val_loss: 2581.1157\n",
      "Epoch 995/1000\n",
      "41/41 [==============================] - 0s 109us/step - loss: 1965.0975 - val_loss: 908.7576\n",
      "Epoch 996/1000\n",
      "41/41 [==============================] - 0s 126us/step - loss: 2140.3225 - val_loss: 2466.1155\n",
      "Epoch 997/1000\n",
      "41/41 [==============================] - 0s 99us/step - loss: 1899.5227 - val_loss: 904.9407\n",
      "Epoch 998/1000\n",
      "41/41 [==============================] - 0s 112us/step - loss: 1994.5533 - val_loss: 2475.2053\n",
      "Epoch 999/1000\n",
      "41/41 [==============================] - 0s 149us/step - loss: 1910.0044 - val_loss: 1001.9447\n",
      "Epoch 1000/1000\n",
      "41/41 [==============================] - 0s 97us/step - loss: 2015.1035 - val_loss: 2490.2397\n"
     ]
    }
   ],
   "source": [
    "train_history = LinearModel.fit(np_train_X , np_train_Y , batch_size=64 , epochs=1000 , verbose=1, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 產生 Predict 2019/04/02 ～ 2019/04/08 所需的Testing feature\n",
    "取 2018/04/02 ～ 2018/04/08 以及網站上的 2019/04/02前一週的資料\n",
    "但沒有2019/04/01所以用2018/04/01代替"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTestX(tp_2018):\n",
    "    findDate = 0\n",
    "    index = 0\n",
    "    test_list = []\n",
    "    for d in tp_2018:\n",
    "        if d[0] == '20180402':\n",
    "            findDate = 1\n",
    "            index += 1\n",
    "            test_list += d[1:]\n",
    "        if findDate is 1:\n",
    "            index += 1\n",
    "            test_list += d[1:]\n",
    "            #test_list.append(d)\n",
    "        if index is 7:\n",
    "            break\n",
    "    return test_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "testList = getTestX(tp_2018)\n",
    "test_2019_list = ['28756', '1887', '6.56', '29140', '1933', '6.63', '30093', '1892', '6.29', '29673', '2054', '6.92', '25810', '2155', '8.35', '24466', '2298', '9.39', '23895', '1655', '6.92']\n",
    "test_X = testList + test_2019_list\n",
    "np_test_X = np.array(test_X)\n",
    "#print(test_X)\n",
    "#print(len(test_X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[28236.53  29439.281 27261.932 27617.697 27167.855 25013.686 23651.664]\n"
     ]
    }
   ],
   "source": [
    "#print(np_test_X.shape)\n",
    "test = np_test_X.reshape(1, 42)\n",
    "#print(test.shape)\n",
    "test_Y = LinearModel.predict(test)\n",
    "print(test_Y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveCSV(test_Y):\n",
    "    date = 20190402\n",
    "    d_list = []\n",
    "    temp_list = []\n",
    "    index = 0\n",
    "    for t in test_Y:\n",
    "        temp_list.append(str(date+index))\n",
    "        temp_list.append(t)\n",
    "        d_list.append(temp_list)\n",
    "        temp_list = []\n",
    "        index += 1\n",
    "    df = pd.DataFrame(d_list, columns=['date', 'peak_load(MW)'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = saveCSV(test_Y[0])\n",
    "df.to_csv('submission.csv', index=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2019.04.01\n",
    "P76071200\n",
    "資工所 馬崇堯"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
